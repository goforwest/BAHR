"""
Analyze V2 endpoint - Enhanced prosodic analysis with full explainability.

This endpoint uses BahrDetectorV2 which provides:
- Rule-based detection (not pattern memorization)
- Complete explainability (shows which Zihafat were applied)
- Full support for all 16 classical Arabic meters
- Confidence scoring with match quality indicators
- Bilingual explanations (Arabic + English)
"""

import logging
from fastapi import APIRouter, HTTPException, status
from app.schemas.analyze import AnalyzeRequest, AnalyzeResponse, BahrInfo, RhymeInfo
from app.core.normalization import normalize_arabic_text
from app.core.taqti3 import perform_taqti3
from app.core.prosody.detector_v2 import BahrDetectorV2
from app.core.quality import analyze_verse_quality
from app.core.phonetics import text_to_phonetic_pattern
from app.core.rhyme import analyze_verse_rhyme
from app.db.redis import cache_get, cache_set, generate_cache_key

logger = logging.getLogger(__name__)

router = APIRouter()

# Initialize BahrDetectorV2 (singleton)
bahr_detector_v2 = BahrDetectorV2()
logger.info(f"BahrDetectorV2 initialized: {bahr_detector_v2.get_statistics()['total_meters']} meters, {bahr_detector_v2.get_statistics()['total_patterns']} patterns")


@router.post(
    "/",
    response_model=AnalyzeResponse,
    status_code=status.HTTP_200_OK,
    summary="Analyze Arabic verse (V2 - Enhanced with Explainability)",
    description="""
    Perform enhanced prosodic analysis on Arabic poetry using rule-based detection.

    **NEW in V2:**
    - âœ¨ Complete explainability: Shows which Zihafat/Ilal were applied
    - ğŸ¯ Match quality indicators (exact, strong, moderate, weak)
    - ğŸ“Š Rule-based detection (365+ valid patterns generated from classical prosody rules)
    - ğŸŒ Bilingual explanations (Arabic + English)
    - ğŸ“š Full support for all 16 classical Arabic meters

    **Analysis includes:**
    - Taqti3 (prosodic scansion)
    - Bahr detection with confidence scores
    - Transformation tracking (which Zihafat were applied)
    - Quality scoring
    - Rhyme analysis (optional)

    **Returns rich metadata including:**
    - `match_quality`: How well the verse matches the detected meter
    - `transformations`: List of prosodic variations applied
    - `explanation_ar/en`: Human-readable explanation of the match
    """,
    responses={
        200: {
            "description": "Successful analysis with full explainability",
            "content": {
                "application/json": {
                    "example": {
                        "text": "Ø¥Ø°Ø§ ØºØ§Ù…ÙØ±ØªÙ ÙÙŠ Ø´ÙØ±ÙÙÙ Ù…ÙØ±ÙˆÙ…Ù",
                        "taqti3": "ÙØ¹ÙˆÙ„Ù† Ù…ÙØ§Ø¹ÙŠÙ„Ù† ÙØ¹ÙˆÙ„Ù† Ù…ÙØ§Ø¹ÙŠÙ„Ù†",
                        "bahr": {
                            "id": 1,
                            "name_ar": "Ø§Ù„Ø·ÙˆÙŠÙ„",
                            "name_en": "at-Tawil",
                            "confidence": 0.97,
                            "match_quality": "strong",
                            "matched_pattern": "/o////o/o/o/o//o//o/o/o",
                            "transformations": ["base", "Ù‚Ø¨Ø¶", "base", "base"],
                            "explanation_ar": "Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ø²Ø­Ø§ÙØ§Øª: Ù‚Ø¨Ø¶ ÙÙŠ Ø§Ù„Ù…ÙˆØ¶Ø¹ Ø§Ù„Ø«Ø§Ù†ÙŠ",
                            "explanation_en": "Match with variations: qabd at position 2"
                        },
                        "errors": [],
                        "suggestions": ["âœ“ Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ØªØ³Ù‚ Ù…Ø¹ Ø¨Ø­Ø± Ø§Ù„Ø·ÙˆÙŠÙ„"],
                        "score": 97.0
                    }
                }
            }
        },
        400: {"description": "Invalid input"},
        500: {"description": "Server error"}
    }
)
async def analyze_v2(request: AnalyzeRequest) -> AnalyzeResponse:
    """
    Analyze Arabic verse with enhanced explainability (V2).

    This endpoint uses BahrDetectorV2 which provides complete transparency
    about how meter detection works, including which prosodic variations
    (Zihafat and 'Ilal) were applied.

    Args:
        request: Analysis request with text and options

    Returns:
        AnalyzeResponse with taqti3, enhanced bahr detection, and quality score

    Raises:
        HTTPException: 400 for invalid input, 500 for server errors
    """
    try:
        # Step 1: Normalize text
        logger.info(f"[V2] Analyzing verse: {request.text[:50]}...")

        try:
            normalized_text = normalize_arabic_text(
                request.text,
                remove_tashkeel=False,  # Keep diacritics for accurate analysis
                normalize_hamzas=True,
                normalize_alefs=True
            )
        except Exception as e:
            logger.error(f"Text normalization failed: {e}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Failed to normalize text: {str(e)}"
            )

        if not normalized_text or not normalized_text.strip():
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Text is empty after normalization"
            )

        # Step 2: Check Redis cache
        cache_key = generate_cache_key(normalized_text + "_v2")  # Different cache for v2
        cached_result = None

        try:
            cached_result = await cache_get(cache_key)
            if cached_result:
                logger.info(f"[V2] Cache hit for key: {cache_key}")
                return AnalyzeResponse(**cached_result)
        except Exception as e:
            logger.warning(f"Cache read failed (continuing without cache): {e}")

        logger.info(f"[V2] Cache miss for key: {cache_key}, performing analysis")

        # Step 3: Detect bahr using BahrDetectorV2 (with 100% accuracy features!)
        # NOTE: We do bahr detection FIRST so we can use it for accurate taqti3
        bahr_info = None
        confidence = 0.0

        if request.detect_bahr:
            try:
                # Get phonetic pattern (use precomputed if provided, otherwise extract)
                if request.precomputed_pattern:
                    phonetic_pattern = request.precomputed_pattern
                    logger.info(f"[V2] Using pre-computed pattern: {phonetic_pattern}")
                else:
                    # Split verse into hemistichs if needed (detector expects single hemistich)
                    import re

                    # Try explicit separators first: *** or 3+ spaces
                    hemistichs = re.split(r'\s*[*Ã—â€¢]{2,}\s*|\s{3,}', normalized_text)

                    if len(hemistichs) >= 2:
                        # Found explicit separator
                        first_hemistich = hemistichs[0].strip()
                    else:
                        # No explicit separator - split at midpoint by words
                        # Arabic verses typically have equal-length hemistichs
                        words = normalized_text.strip().split()
                        if len(words) > 8:  # If verse has many words, likely has 2 hemistichs
                            mid = len(words) // 2
                            first_hemistich = ' '.join(words[:mid])
                            logger.info(f"[V2] No separator found, splitting at midpoint: {mid} words")
                        else:
                            # Short text, use as-is
                            first_hemistich = normalized_text

                    # Extract pattern for first hemistich
                    phonetic_pattern = text_to_phonetic_pattern(first_hemistich)
                    logger.info(f"[V2] Extracted phonetic pattern from first hemistich: {phonetic_pattern}")

                # Use BahrDetectorV2 with 100% accuracy features:
                # 1. Smart disambiguation (resolves ties between overlapping patterns)
                # 2. Expected meter support (provides targeted disambiguation when known)
                detection_results = bahr_detector_v2.detect(
                    phonetic_pattern,
                    top_k=1,
                    expected_meter_ar=request.expected_meter  # Enables targeted disambiguation if provided
                )

                if detection_results:
                    detection_result = detection_results[0]
                    # Extract explanation parts (bilingual)
                    explanation_full = detection_result.explanation
                    if " | " in explanation_full:
                        explanation_ar, explanation_en = explanation_full.split(" | ", 1)
                    else:
                        explanation_ar = explanation_full
                        explanation_en = explanation_full

                    bahr_info = BahrInfo(
                        id=detection_result.meter_id,
                        name_ar=detection_result.meter_name_ar,
                        name_en=detection_result.meter_name_en,
                        confidence=detection_result.confidence,
                        # NEW: Explainability fields
                        match_quality=detection_result.match_quality.value,
                        matched_pattern=detection_result.matched_pattern,
                        transformations=detection_result.transformations,
                        explanation_ar=explanation_ar.strip(),
                        explanation_en=explanation_en.strip()
                    )
                    confidence = detection_result.confidence

                    logger.info(
                        f"[V2] Detected: {bahr_info.name_ar} "
                        f"(confidence: {confidence:.2%}, quality: {bahr_info.match_quality}) "
                        f"with transformations: {bahr_info.transformations}"
                    )
                else:
                    logger.info("[V2] No bahr detected with sufficient confidence")

            except Exception as e:
                logger.error(f"[V2] Bahr detection failed: {e}", exc_info=True)
        else:
            logger.info("[V2] Bahr detection skipped (detect_bahr=False)")

        # Step 4: Perform taqti3 (scansion) AFTER bahr detection
        # This allows us to use the detected meter for accurate tafail
        try:
            if bahr_info and bahr_info.id:
                # Use detected bahr for accurate taqti3
                taqti3_result = perform_taqti3(
                    normalized_text,
                    normalize=False,
                    bahr_id=bahr_info.id
                )
                logger.info(f"[V2] Taqti3 with detected bahr {bahr_info.name_ar}: {taqti3_result}")
            else:
                # Fallback to pattern matching if no bahr detected
                taqti3_result = perform_taqti3(normalized_text, normalize=False)
                logger.info(f"[V2] Taqti3 without bahr (pattern matching): {taqti3_result}")

            if not taqti3_result or not taqti3_result.strip():
                logger.warning("Taqti3 returned empty result")
                taqti3_result = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

        except ValueError as e:
            logger.error(f"Taqti3 validation error: {e}")
            # Don't raise error, just set to fallback
            taqti3_result = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        except Exception as e:
            logger.error(f"Taqti3 processing failed: {e}", exc_info=True)
            taqti3_result = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

        # Step 5: Enhanced quality analysis
        try:
            phonetic_pattern = text_to_phonetic_pattern(normalized_text)

            quality_score, quality_errors, quality_suggestions = analyze_verse_quality(
                verse_text=request.text,
                taqti3_result=taqti3_result,
                bahr_id=bahr_info.id if bahr_info else None,
                bahr_name_ar=bahr_info.name_ar if bahr_info else None,
                meter_confidence=confidence,
                detected_pattern=phonetic_pattern,
                expected_pattern=""
            )

            score = quality_score.overall
            suggestions = quality_suggestions if request.suggest_corrections else []

            # Add explainability-based suggestions
            if bahr_info and bahr_info.transformations:
                non_base = [t for t in bahr_info.transformations if t != "base"]
                if not non_base:
                    suggestions.append(f"âœ“ Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ØªØ³Ù‚ Ù…Ø¹ Ø¨Ø­Ø± {bahr_info.name_ar} (Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)")
                elif len(non_base) <= 2:
                    suggestions.append(f"âœ“ Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø¬ÙŠØ¯ Ù…Ø¹ Ø²Ø­Ø§ÙØ§Øª Ù…Ø¹ØªØ§Ø¯Ø©: {', '.join(non_base)}")
                else:
                    suggestions.append(f"âš ï¸ Ø¹Ø¯Ø© Ø²Ø­Ø§ÙØ§Øª Ù…Ø·Ø¨Ù‚Ø©: {', '.join(non_base)}")

            logger.info(
                f"[V2] Quality: overall={score:.2f}, "
                f"meter_accuracy={quality_score.meter_accuracy:.2f}"
            )

        except Exception as e:
            logger.warning(f"Quality analysis failed, using simple scoring: {e}")

            score = round(confidence * 100, 2) if confidence > 0 else 0.0
            score = max(0.0, min(100.0, score))

            suggestions = []
            if confidence >= 0.9:
                suggestions.append("âœ“ Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ØªØ³Ù‚")
            elif confidence >= 0.7:
                suggestions.append("Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø¬ÙŠØ¯ Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø©")
            elif confidence > 0:
                suggestions.append("Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ Ø§Ù„Ø¨ÙŠØª Ø¥Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù„Ù„ØªÙ‚Ø·ÙŠØ¹")

            if not bahr_info and request.detect_bahr:
                suggestions.append("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø± Ø¨Ø«Ù‚Ø© ÙƒØ§ÙÙŠØ©")

        # Step 6: Rhyme analysis (if requested)
        rhyme_info = None
        if request.analyze_rhyme:
            try:
                rhyme_pattern, rhyme_desc_ar, rhyme_desc_en = analyze_verse_rhyme(request.text)

                rhyme_info = RhymeInfo(
                    rawi=rhyme_pattern.qafiyah.rawi,
                    rawi_vowel=rhyme_pattern.qafiyah.rawi_vowel,
                    rhyme_types=[rt.value for rt in rhyme_pattern.rhyme_types],
                    description_ar=rhyme_desc_ar,
                    description_en=rhyme_desc_en
                )

                if request.suggest_corrections:
                    suggestions.append(f"ğŸµ {rhyme_desc_ar}")

                logger.info(f"[V2] Rhyme: rawi={rhyme_pattern.qafiyah.rawi}")

            except Exception as e:
                logger.warning(f"Rhyme analysis failed: {e}")

        # Step 7: Build response
        response = AnalyzeResponse(
            text=request.text,
            taqti3=taqti3_result,
            bahr=bahr_info,
            rhyme=rhyme_info,
            errors=[],
            suggestions=suggestions if request.suggest_corrections else [],
            score=score
        )

        # Step 8: Cache result (TTL: 24 hours)
        try:
            response_dict = response.model_dump()
            await cache_set(cache_key, response_dict, ttl=86400)
            logger.info(f"[V2] Cached analysis result with key: {cache_key}")
        except Exception as e:
            logger.warning(f"Failed to cache result: {e}")

        # Step 9: Return response
        return response

    except HTTPException:
        raise
    except ValueError as e:
        logger.error(f"Validation error: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Unexpected error during analysis: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An unexpected error occurred during analysis. Please try again."
        )
