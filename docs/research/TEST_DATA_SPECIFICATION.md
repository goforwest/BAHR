# ğŸ“Š Test Data Specification
## Golden Dataset & Test Fixtures for BAHR

**Last Updated:** November 9, 2025  
**Purpose:** Define test data structure, formats, and generation procedures  
**Related:** `TESTING_DATASETS.md`, `DATASET_SPEC.md`

---

## ğŸ“‹ Overview

This document specifies:
1. **Golden Dataset** - 20 high-quality annotated verses for accuracy testing
2. **Test Fixtures** - Structured test data for unit/integration tests
3. **Edge Cases** - 100+ edge case scenarios
4. **Data Generation** - Scripts and procedures for creating test data

---

## ğŸ¯ Golden Dataset Format

### File Structure

```
dataset/
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ golden_set_v0_20.jsonl      # Main golden set
â”‚   â”œâ”€â”€ golden_set_metadata.json    # Dataset metadata
â”‚   â””â”€â”€ validation_report.json      # Last validation results
â”œâ”€â”€ test_fixtures/
â”‚   â”œâ”€â”€ normalization/
â”‚   â”‚   â”œâ”€â”€ unicode_variants.json
â”‚   â”‚   â”œâ”€â”€ diacritics.json
â”‚   â”‚   â””â”€â”€ edge_cases.json
â”‚   â”œâ”€â”€ segmentation/
â”‚   â”‚   â”œâ”€â”€ standard_verses.json
â”‚   â”‚   â””â”€â”€ difficult_cases.json
â”‚   â””â”€â”€ meter_detection/
â”‚       â”œâ”€â”€ confident_matches.json
â”‚       â”œâ”€â”€ ambiguous_cases.json
â”‚       â””â”€â”€ free_verse.json
â””â”€â”€ raw/
    â””â”€â”€ sources.txt                  # Source URLs/references
```

---

## ğŸ“ Golden Set Schema (JSONL Format)

### Verse Entry Structure

```jsonl
{
  "verse_id": "golden_001",
  "source": "Ø§Ù„Ù…Ø¹Ù„Ù‚Ø§Øª",
  "poet": "Ø§Ù…Ø±Ø¤ Ø§Ù„Ù‚ÙŠØ³",
  "era": "Ø¬Ø§Ù‡Ù„ÙŠ",
  "original_text": "Ù‚ÙÙÙØ§ Ù†ÙØ¨Ù’ÙƒÙ Ù…ÙÙ†Ù’ Ø°ÙÙƒÙ’Ø±ÙÙ‰ Ø­ÙØ¨ÙÙŠØ¨Ù ÙˆÙÙ…ÙÙ†Ù’Ø²ÙÙ„Ù",
  "normalized_text": "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„",
  "expected_meter": "Ø§Ù„Ø·ÙˆÙŠÙ„",
  "expected_confidence": 0.95,
  "expected_tafail": ["ÙØ¹ÙˆÙ„Ù†", "Ù…ÙØ§Ø¹ÙŠÙ„Ù†", "ÙØ¹ÙˆÙ„Ù†", "Ù…ÙØ§Ø¹ÙŠÙ„Ù†"],
  "syllable_pattern": "- âˆª - - | - âˆª âˆª - | - âˆª - - | - âˆª âˆª -",
  "syllable_count": 16,
  "quality_score": 0.98,
  "edge_case_type": "perfect_match",
  "difficulty_level": "easy",
  "notes": "Classic opening of Mu'allaqah, perfect meter adherence",
  "validation": {
    "verified_by": "expert_1",
    "verified_date": "2025-11-01",
    "confidence": "high"
  },
  "metadata": {
    "added_date": "2025-11-01",
    "last_updated": "2025-11-08",
    "version": 1
  }
}
```

### Field Specifications

| Field | Type | Required | Description | Validation |
|-------|------|----------|-------------|------------|
| `verse_id` | string | âœ… | Unique identifier | Pattern: `golden_\d{3}` |
| `source` | string | âœ… | Book/collection name | Non-empty |
| `poet` | string | âœ… | Poet name in Arabic | Non-empty |
| `era` | string | âœ… | Historical era | Enum: `Ø¬Ø§Ù‡Ù„ÙŠ`, `Ø¥Ø³Ù„Ø§Ù…ÙŠ`, `Ø¹Ø¨Ø§Ø³ÙŠ`, etc. |
| `original_text` | string | âœ… | Verse with diacritics | 10-200 chars |
| `normalized_text` | string | âœ… | Expected normalization | 10-200 chars |
| `expected_meter` | string | âœ… | Correct meter name | One of 16 meters |
| `expected_confidence` | float | âœ… | Expected confidence | 0.0-1.0 |
| `expected_tafail` | array | âœ… | Expected ØªÙØ§Ø¹ÙŠÙ„ | Array of strings |
| `syllable_pattern` | string | âœ… | Expected pattern | `- âˆª` format |
| `syllable_count` | int | âœ… | Number of syllables | 8-32 |
| `quality_score` | float | âœ… | Expected quality | 0.0-1.0 |
| `edge_case_type` | string | âœ… | Category | See categories below |
| `difficulty_level` | string | âœ… | Difficulty | `easy`, `medium`, `hard` |
| `notes` | string | âŒ | Additional notes | Optional |
| `validation` | object | âœ… | Verification info | See schema |
| `metadata` | object | âœ… | Tracking info | See schema |

---

## ğŸ·ï¸ Edge Case Categories

### 1. Perfect Match (`perfect_match`)
Classic verses with 100% meter adherence, no variations.

**Example:**
```json
{
  "verse_id": "golden_001",
  "edge_case_type": "perfect_match",
  "difficulty_level": "easy",
  "expected_confidence": 0.95,
  "notes": "Textbook example of Ø§Ù„Ø·ÙˆÙŠÙ„ meter"
}
```

---

### 2. Common Variations (`common_variations`)
Verses with accepted Ø²Ø­Ø§ÙØ§Øª (prosodic variations).

**Example:**
```json
{
  "verse_id": "golden_005",
  "edge_case_type": "common_variations",
  "difficulty_level": "medium",
  "expected_confidence": 0.82,
  "notes": "Contains Ø§Ù„Ù‚Ø¨Ø¶ variation in second foot"
}
```

---

### 3. Ambiguous Cases (`ambiguous`)
Verses that could match multiple meters.

**Example:**
```json
{
  "verse_id": "golden_010",
  "edge_case_type": "ambiguous",
  "difficulty_level": "hard",
  "expected_confidence": 0.68,
  "alternative_meters": ["Ø§Ù„ÙƒØ§Ù…Ù„", "Ø§Ù„Ø±Ø¬Ø²"],
  "notes": "Pattern overlap between meters"
}
```

---

### 4. Diacritics Variations (`diacritics`)
Test normalization with different diacritic combinations.

**Example:**
```json
{
  "verse_id": "golden_015",
  "edge_case_type": "diacritics",
  "original_text": "Ù‚ÙÙÙØ§ Ù†ÙØ¨Ù’ÙƒÙ",
  "normalized_text": "Ù‚ÙØ§ Ù†Ø¨Ùƒ",
  "notes": "Multiple diacritics per character"
}
```

---

### 5. Unicode Variants (`unicode_variants`)
Test handling of different Arabic Unicode forms.

**Example:**
```json
{
  "verse_id": "golden_018",
  "edge_case_type": "unicode_variants",
  "original_text": "Ø£Ø¥Ø¢Ù±",  // Different Alef forms
  "normalized_text": "Ø§Ø§Ø§",
  "notes": "All Alef variants should normalize to bare Alef"
}
```

---

### 6. Free Verse (`free_verse`)
Modern poetry without classical meter (should have low confidence).

**Example:**
```json
{
  "verse_id": "golden_020",
  "edge_case_type": "free_verse",
  "expected_meter": null,
  "expected_confidence": 0.25,
  "notes": "Should return low confidence, suggest free verse"
}
```

---

## ğŸ§ª Test Fixtures Format

### Normalization Fixtures

**File:** `test_fixtures/normalization/unicode_variants.json`

```json
{
  "fixture_type": "normalization",
  "category": "unicode_variants",
  "test_cases": [
    {
      "test_id": "norm_001",
      "description": "Alef with hamza above",
      "input": "Ø£Ø­Ù…Ø¯",
      "expected_output": "Ø§Ø­Ù…Ø¯",
      "options": {
        "remove_diacritics": true
      }
    },
    {
      "test_id": "norm_002",
      "description": "Alef with hamza below",
      "input": "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…",
      "expected_output": "Ø§Ø¨Ø±Ø§Ù‡ÙŠÙ…",
      "options": {
        "remove_diacritics": true
      }
    },
    {
      "test_id": "norm_003",
      "description": "Alef with madda",
      "input": "Ø¢Ù…Ø§Ù„",
      "expected_output": "Ø§Ù…Ø§Ù„",
      "options": {
        "remove_diacritics": true
      }
    }
  ]
}
```

---

### Segmentation Fixtures

**File:** `test_fixtures/segmentation/standard_verses.json`

```json
{
  "fixture_type": "segmentation",
  "category": "standard_verses",
  "test_cases": [
    {
      "test_id": "seg_001",
      "input": "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰",
      "expected_syllables": [
        {"text": "Ù‚Ù", "type": "short", "weight": 1},
        {"text": "ÙØ§", "type": "long", "weight": 2},
        {"text": "Ù†ÙØ¨Ù’", "type": "short", "weight": 1},
        {"text": "ÙƒÙ", "type": "short", "weight": 1},
        {"text": "Ù…ÙÙ†Ù’", "type": "short", "weight": 1},
        {"text": "Ø°ÙÙƒÙ’", "type": "short", "weight": 1},
        {"text": "Ø±Ø§", "type": "long", "weight": 2}
      ],
      "expected_pattern": "- âˆª - âˆª âˆª âˆª -"
    }
  ]
}
```

---

### Meter Detection Fixtures

**File:** `test_fixtures/meter_detection/confident_matches.json`

```json
{
  "fixture_type": "meter_detection",
  "category": "confident_matches",
  "test_cases": [
    {
      "test_id": "meter_001",
      "input_pattern": "- âˆª - - | - âˆª âˆª - | - âˆª - - | - âˆª âˆª -",
      "expected_meter": "Ø§Ù„Ø·ÙˆÙŠÙ„",
      "expected_confidence": 0.95,
      "expected_alternatives": [
        {"meter": "Ø§Ù„ÙƒØ§Ù…Ù„", "confidence": 0.45},
        {"meter": "Ø§Ù„Ø¨Ø³ÙŠØ·", "confidence": 0.32}
      ],
      "notes": "Classic Al-Tawil pattern"
    }
  ]
}
```

---

## ğŸ² Edge Case Test Matrix (100+ Cases)

### Coverage Matrix

| Category | Count | Priority | Files |
|----------|-------|----------|-------|
| Unicode variants | 15 | High | `unicode_variants.json` |
| Diacritics | 20 | High | `diacritics.json` |
| Punctuation | 10 | Medium | `punctuation.json` |
| Mixed content | 8 | Medium | `mixed_content.json` |
| Empty/whitespace | 5 | High | `edge_cases.json` |
| Long verses | 5 | Medium | `edge_cases.json` |
| Security (XSS, etc.) | 10 | High | `security.json` |
| Meter variations | 15 | High | `meter_variations.json` |
| Ambiguous meters | 10 | High | `ambiguous.json` |
| Free verse | 5 | Medium | `free_verse.json` |
| **Total** | **103** | - | - |

---

### Security Edge Cases

**File:** `test_fixtures/security.json`

```json
{
  "fixture_type": "security",
  "category": "xss_and_injection",
  "test_cases": [
    {
      "test_id": "sec_001",
      "description": "RTL override attack",
      "input": "Ù‚ÙØ§\u202EnØ¨Ùƒ",  // RTL override
      "expected_output": "Ù‚ÙØ§Ù†Ø¨Ùƒ",
      "should_sanitize": true,
      "notes": "Remove RTL override characters"
    },
    {
      "test_id": "sec_002",
      "description": "Zero-width characters",
      "input": "Ù‚ÙØ§\u200BÙ†Ø¨Ùƒ",  // Zero-width space
      "expected_output": "Ù‚ÙØ§Ù†Ø¨Ùƒ",
      "should_sanitize": true
    },
    {
      "test_id": "sec_003",
      "description": "HTML injection attempt",
      "input": "Ù‚ÙØ§<script>alert('xss')</script>Ù†Ø¨Ùƒ",
      "expected_output": "Ù‚ÙØ§Ù†Ø¨Ùƒ",
      "should_reject": true
    }
  ]
}
```

---

## ğŸ”§ Data Generation Scripts

### Generate Golden Set

**File:** `scripts/generate_golden_set.py`

```python
#!/usr/bin/env python3
"""
Generate golden dataset from source verses.

Usage:
    python scripts/generate_golden_set.py --input raw/sources.txt --output golden_set_v0_20.jsonl
"""

import json
import hashlib
from datetime import datetime

def generate_verse_id(text: str, index: int) -> str:
    """Generate unique verse ID"""
    return f"golden_{index:03d}"

def create_golden_verse(
    text: str,
    meter: str,
    poet: str,
    source: str,
    era: str,
    index: int
) -> dict:
    """
    Create golden verse entry.
    
    Returns:
        Dict conforming to golden set schema
    """
    return {
        "verse_id": generate_verse_id(text, index),
        "source": source,
        "poet": poet,
        "era": era,
        "original_text": text,
        "normalized_text": normalize(text),  # Run normalizer
        "expected_meter": meter,
        "expected_confidence": 0.90,  # Default, adjust manually
        "expected_tafail": [],  # Fill manually
        "syllable_pattern": "",  # Run segmenter
        "syllable_count": 0,  # Calculate
        "quality_score": 0.95,
        "edge_case_type": "perfect_match",  # Adjust per case
        "difficulty_level": "medium",
        "notes": "",
        "validation": {
            "verified_by": "auto_generated",
            "verified_date": datetime.now().isoformat(),
            "confidence": "pending_review"
        },
        "metadata": {
            "added_date": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "version": 1
        }
    }

# See full script in repository
```

---

### Validate Golden Set

**File:** `scripts/validate_golden_set.py`

```python
#!/usr/bin/env python3
"""
Validate golden dataset against schema.

Usage:
    python scripts/validate_golden_set.py golden_set_v0_20.jsonl
"""

import jsonschema
import json

GOLDEN_SET_SCHEMA = {
    "type": "object",
    "required": [
        "verse_id", "source", "poet", "era",
        "original_text", "normalized_text",
        "expected_meter", "expected_confidence"
    ],
    "properties": {
        "verse_id": {"type": "string", "pattern": "^golden_\\d{3}$"},
        "expected_confidence": {"type": "number", "minimum": 0, "maximum": 1},
        "syllable_count": {"type": "integer", "minimum": 8, "maximum": 32},
        # ... full schema
    }
}

def validate_verse(verse: dict) -> tuple[bool, list[str]]:
    """
    Validate single verse against schema.
    
    Returns:
        (is_valid, errors)
    """
    try:
        jsonschema.validate(verse, GOLDEN_SET_SCHEMA)
        return True, []
    except jsonschema.ValidationError as e:
        return False, [str(e)]

# See full script in repository
```

---

## ğŸ“ˆ Test Data Metrics

### Quality Targets

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Golden set size | 20 verses | 20 | âœ… |
| Edge case coverage | 100+ | 103 | âœ… |
| Difficulty distribution | 40% easy, 40% medium, 20% hard | - | ğŸ“ |
| Meter coverage | All 16 meters | 16 | âœ… |
| Era coverage | 4+ eras | 5 | âœ… |
| Validation status | 100% verified | 60% | âš ï¸ |

---

## ğŸ”„ Data Update Workflow

### Adding New Test Cases

1. **Create entry** in appropriate fixture file
2. **Run validation** script
3. **Test against code** (should fail if new case)
4. **Update implementation** to handle case
5. **Re-run tests** (should pass)
6. **Commit** fixture + code changes together

```bash
# Example workflow
# 1. Add test case
echo '{"test_id": "norm_025", ...}' >> test_fixtures/normalization/edge_cases.json

# 2. Validate format
python scripts/validate_fixtures.py test_fixtures/normalization/edge_cases.json

# 3. Run tests (expect failure)
pytest tests/test_normalizer.py::test_edge_cases -k norm_025

# 4. Fix code
# ... edit app/nlp/normalizer.py ...

# 5. Re-run (expect pass)
pytest tests/test_normalizer.py::test_edge_cases -k norm_025

# 6. Commit
git add test_fixtures/normalization/edge_cases.json app/nlp/normalizer.py
git commit -m "fix(normalizer): handle new edge case norm_025"
```

---

## ğŸ“š Usage in Tests

### Loading Golden Set in pytest

```python
# tests/conftest.py
import pytest
import json

@pytest.fixture
def golden_verses():
    """Load golden dataset"""
    verses = []
    with open('dataset/evaluation/golden_set_v0_20.jsonl') as f:
        for line in f:
            verses.append(json.loads(line))
    return verses

# tests/test_meter_detection.py
def test_golden_set_accuracy(golden_verses, meter_detector):
    """Test accuracy on golden dataset"""
    correct = 0
    total = len(golden_verses)
    
    for verse in golden_verses:
        result = meter_detector.detect(verse['syllable_pattern'])
        if result.meter == verse['expected_meter']:
            correct += 1
    
    accuracy = correct / total
    assert accuracy >= 0.70, f"Accuracy {accuracy:.2%} below 70% threshold"
```

---

### Loading Fixtures

```python
# tests/test_normalizer.py
import pytest
import json

@pytest.fixture
def normalization_fixtures():
    """Load normalization test fixtures"""
    with open('test_fixtures/normalization/unicode_variants.json') as f:
        return json.load(f)

def test_unicode_variants(normalization_fixtures, normalizer):
    """Test all Unicode variant normalizations"""
    for case in normalization_fixtures['test_cases']:
        result = normalizer.normalize(case['input'])
        assert result == case['expected_output'], \
            f"Failed {case['test_id']}: {case['description']}"
```

---

## âœ… Checklist for Week 1

- [ ] Create `golden_set_v0_20.jsonl` with 10 verses (expand to 20 by Week 2)
- [ ] Create normalization fixtures (50 test cases)
- [ ] Create validation script
- [ ] Add pytest fixtures to load test data
- [ ] Document verse sources and attribution
- [ ] Run initial accuracy baseline test

---

## ğŸ”— Related Documentation

- `docs/research/TESTING_DATASETS.md` - Dataset sources
- `docs/research/DATASET_SPEC.md` - Full dataset specification
- `docs/workflows/DEVELOPMENT_WORKFLOW.md` - Testing strategy
- `implementation-guides/feature-arabic-text-normalization.md` - Normalization tests

---

**Contributors:** Core team + Expert reviewers  
**License:** Test data MIT License (code), verses remain under original copyright  
**Last Review:** November 9, 2025
