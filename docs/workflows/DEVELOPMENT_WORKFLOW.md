# âš™ï¸ Ø¯Ù„ÙŠÙ„ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
## Git Workflow + Testing + Deployment Pipeline

---

## ğŸ“‹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

Ø¯Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ù…Ø´Ø±ÙˆØ¹ Ø¨ÙØ­Ù’Ø± Ù…Ù† Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰:
- **Git Workflow** Ù…Ù†Ø¸Ù… ÙˆØ¢Ù…Ù†
- **Code Quality** Ø¹Ø§Ù„ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
- **Testing Strategy** Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ØªØ¯Ø±Ø¬Ø©
- **CI/CD Pipeline** Ù…Ø¤ØªÙ…Øª Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
- **Deployment** Ø¢Ù…Ù† ÙˆÙ…Ø±Ø§Ù‚Ø¨
- **Team Collaboration** ÙØ¹Ù‘Ø§Ù„Ø©

---

## ğŸŒ¿ Git Workflow Strategy

### Branch Structure

```
Git Branch Strategy (Git Flow):

main (production)
â”œâ”€â”€ develop (integration)
â”‚   â”œâ”€â”€ feature/user-authentication
â”‚   â”œâ”€â”€ feature/prosody-analysis-engine
â”‚   â”œâ”€â”€ feature/competition-system
â”‚   â””â”€â”€ feature/arabic-nlp-integration
â”œâ”€â”€ release/v1.0.0
â”œâ”€â”€ hotfix/critical-security-fix
â””â”€â”€ docs/api-documentation
```

### Branch Types

```yaml
Branch Types:
  main:
    purpose: "Production-ready code"
    protection: "Required reviews, status checks"
    deployment: "Auto-deploy to production"
    
  develop:
    purpose: "Integration branch for features"
    protection: "Required status checks"
    deployment: "Auto-deploy to staging"
    
  feature/*:
    purpose: "New features and enhancements" 
    naming: "feature/short-description"
    source: "develop"
    target: "develop"
    
  release/*:
    purpose: "Prepare new release"
    naming: "release/v1.2.0"
    source: "develop"
    target: "main"
    
  hotfix/*:
    purpose: "Critical fixes for production"
    naming: "hotfix/issue-description"
    source: "main"
    target: "main + develop"
    
  docs/*:
    purpose: "Documentation updates"
    naming: "docs/topic-name"
    source: "develop"
    target: "develop"
```

---

## ğŸ”„ Development Workflow

### 1. Feature Development Process

```bash
# 1. Start new feature
git checkout develop
git pull origin develop
git checkout -b feature/prosody-analyzer

# 2. Development cycle
# - Write code
# - Write tests  
# - Update documentation

# 3. Regular commits with conventional format
git add .
git commit -m "feat(prosody): add Arabic meter detection algorithm

- Implement pattern matching for classical meters
- Add confidence scoring system
- Include unit tests for meter detection
- Update API documentation

Closes #123"

# 4. Keep feature branch updated
git checkout develop
git pull origin develop
git checkout feature/prosody-analyzer
git merge develop

# 5. Push feature branch
git push -u origin feature/prosody-analyzer

# 6. Create Pull Request
# - Fill PR template
# - Request reviews
# - Link related issues
# - Add labels and milestone
```

### 2. Commit Message Convention

```
Commit Message Format:
<type>(<scope>): <description>

[optional body]

[optional footer]

Types:
  feat: A new feature
  fix: A bug fix
  docs: Documentation only changes
  style: Code style changes (formatting, etc.)
  refactor: Code refactoring
  perf: Performance improvements
  test: Adding or modifying tests
  chore: Build process or auxiliary tool changes

Examples:
  feat(api): add user authentication endpoints
  fix(prosody): resolve meter detection accuracy issue
  docs(readme): update installation instructions
  test(analysis): add unit tests for text normalization
  refactor(database): optimize queries for better performance
```

### 3. Code Review Process

```yaml
Code Review Checklist:
  
  Functionality:
    - âœ… Feature works as expected
    - âœ… Edge cases are handled
    - âœ… Error scenarios covered
    - âœ… Performance considerations
    
  Code Quality:
    - âœ… Follows project conventions
    - âœ… DRY principle applied
    - âœ… Readable and maintainable
    - âœ… Proper error handling
    - âœ… Security considerations
    
  Testing:
    - âœ… Unit tests written
    - âœ… Integration tests included
    - âœ… Test coverage > 80%
    - âœ… Tests pass locally and in CI
    
  Documentation:
    - âœ… API documentation updated
    - âœ… README updated if needed
    - âœ… Code comments for complex logic
    - âœ… Database schema changes documented
```

---

## ğŸ§ª Testing Strategy

### Test Pyramid Structure

```
Testing Pyramid:

           /\
          /  \
         / E2E\ (Few)
        /______\
       /        \
      /Integration\ (Some)
     /____________\
    /              \
   /   Unit Tests   \ (Many)
  /__________________\

E2E (5%): Full user journeys
Integration (15%): API + Database + External services  
---

## ğŸ§ª Testing Strategy (Ù…ÙØ­Ø¯Ù‘Ø«Ø©)

### Test Pyramid Structure

```
Testing Pyramid:

           /\
          /  \
         / E2E\ (5% - Few but Critical)
        /______\
       /        \
      /Integration\ (15% - Key Flows)
     /____________\
    /              \
   /   Unit Tests   \ (80% - Fast & Comprehensive)
  /__________________\

E2E (5%): Full user journeys
Integration (15%): API + Database + External services  
Unit (80%): Individual functions and components
```

### Component-Specific Coverage Targets:

```yaml
Backend Components:

  Normalizer (app/core/prosody/normalizer.py):
    Coverage Target: 95%
    Test Cases: 60+
    Focus Areas:
      - Diacritics removal (10 cases)
      - Hamza normalization (8 cases)
      - Ta Marbuta handling (5 cases)
      - Mixed Arabic/English text (8 cases)
      - Special characters & numbers (10 cases)
      - Edge cases: empty string, very long text, etc. (10 cases)
      - Shadda decomposition (6 cases)
      - TanwÄ«n pause rules (8 cases)

  Segmenter (app/core/prosody/segmenter.py):
    Coverage Target: 90%
    Test Cases: 40+
    Focus Areas:
      - Syllable type detection (CV, CVV, CVC) (12 cases)
      - Classical poetry verses (10 cases)
      - Modern poetry variations (8 cases)
      - Madd letter handling (6 cases)
      - SukÅ«n cluster resolution (4 cases)

  Pattern Matcher (app/core/prosody/pattern_matcher.py):
    Coverage Target: 90%
    Test Cases: 50+
    Focus Areas:
      - Each taf'ila pattern (8 Ã— 5 = 40 cases)
      - ZihÄfÄt variations (10 cases)

  Meter Detector (app/core/prosody/meter_detector.py):
    Coverage Target: 85%
    Test Cases: 170+
    Focus Areas:
      - Each meter (16 meters Ã— 10 examples = 160 cases)
      - Ambiguous cases (10 cases)

  API Endpoints (app/api/v1/endpoints/*.py):
    Coverage Target: 85%
    Test Cases: 50+
    Focus Areas:
      - Happy paths (15 cases)
      - Authentication & authorization (10 cases)
      - Input validation errors (15 cases)
      - Rate limiting (5 cases)
      - Error responses (5 cases)

Frontend Components:

  TextInput Component:
    Coverage Target: 80%
    Test Cases: 15+
    Focus Areas:
      - RTL text handling
      - Character limit enforcement
      - Keyboard shortcuts
      - Copy/paste behavior

  ResultsDisplay Component:
    Coverage Target: 85%
    Test Cases: 20+
    Focus Areas:
      - Rendering with different confidence levels
      - Alternative meters display
      - Export functionality
      - Loading states

  Analysis Hook (useAnalyze):
    Coverage Target: 90%
    Test Cases: 12+
    Focus Areas:
      - API call success
      - Error handling
      - Loading states
      - Cache management
```

### Edge Cases & Critical Test Scenarios:

```yaml
Text Processing Edge Cases:
  1. Empty text: ""
  2. Very long text: 10,000+ characters
  3. Only spaces: "     "
  4. Only punctuation: "ØŒØ›!ØŸ"
  5. Mixed Arabic/English: "Poetry is Ø´Ø¹Ø±"
  6. Arabic numerals: "Ø§Ù„Ø¯Ø±Ø³ Ù¡Ù¢Ù£"
  7. Latin numerals: "Ø§Ù„Ù‚ØµÙŠØ¯Ø© 123"
  8. Special Arabic chars: "ï·² ï·º"
  9. Emoji in text: "Ø§Ù„Ø´Ø¹Ø± ğŸ˜Š"
  10. Repeated characters: "Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§"
  11. No vowels: "ÙƒØªØ¨"
  12. All diacritics: "ÙƒÙØªÙØ¨ÙŒ"
  13. Broken Arabic: "Ø£Ø¢Ø¥Ø¦Ø¤Ø¡"
  14. Poetry with typos: "Ù‚ÙØ£ Ù†Ø¨Úª"
  15. Half-verse only: "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰"

Meter Detection Edge Cases:
  1. Perfect classical verse
  2. Verse with one zihÄf
  3. Verse with multiple zihÄfÄt
  4. Modern poetry (free verse)
  5. Sha'bi/nabati poetry
  6. Broken meter (intentional)
  7. Prose mistaken for poetry
  8. Mixed meters in same text
  9. Very short text (< 10 words)
  10. Incomplete verse (missing hemistich)

API Edge Cases:
  1. Concurrent requests from same user
  2. Malformed JSON
  3. Missing required fields
  4. Extra unexpected fields
  5. SQL injection attempts
  6. XSS attempts in text field
  7. Extremely large payload (> 10MB)
  8. Rate limit exceeded (101st request)
  9. Expired authentication token
  10. Invalid authentication token
```

### Performance Regression Tests:

```python
# tests/performance/test_regression.py
import pytest
import time
from app.core.prosody.analyzer import ProsodyAnalyzer

class TestPerformanceRegression:
    """Ensure performance doesn't degrade with changes"""
    
    @pytest.fixture
    def analyzer(self):
        return ProsodyAnalyzer()
    
    @pytest.mark.slow
    def test_normalization_performance(self, analyzer, benchmark):
        """Normalizer should process 1000 chars in < 10ms"""
        text = "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„ " * 50  # ~1500 chars
        
        def normalize():
            return analyzer.normalizer.normalize(text)
        
        result = benchmark(normalize)
        
        # Assert performance target
        assert benchmark.stats['mean'] < 0.010  # < 10ms average
    
    @pytest.mark.slow
    def test_analysis_performance(self, analyzer, benchmark):
        """Full analysis should complete in < 500ms (P95)"""
        verse = "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„"
        
        def analyze():
            return analyzer.analyze(verse)
        
        result = benchmark(analyze)
        
        # P95 should be under 500ms
        assert benchmark.stats['stddev'] < 0.1  # Low variance
        assert result['processing_time_ms'] < 500
    
    @pytest.mark.slow
    def test_batch_analysis_performance(self, analyzer, benchmark):
        """Batch of 10 verses should complete in < 3 seconds"""
        verses = [
            "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„",
            "Ø£Ø±Ù‰ Ø§Ù„Ø¯Ù‡Ø± Ù…Ø®ØªÙ„Ù Ø§Ù„Ø­ÙˆØ§Ø¯Ø«",
            "Ø¹Ù„Ù‰ Ù‚Ø¯Ø± Ø£Ù‡Ù„ Ø§Ù„Ø¹Ø²Ù… ØªØ£ØªÙŠ Ø§Ù„Ø¹Ø²Ø§Ø¦Ù…"
        ] * 4  # 12 verses
        
        start = time.time()
        results = [analyzer.analyze(v) for v in verses]
        duration = time.time() - start
        
        assert duration < 6.0  # < 6s for 12 verses
        assert all(r['success'] for r in results)
```

### Testing Environment Setup (Ù…Ø­Ø¯Ù‘Ø«)

```yaml
# pytest.ini
[tool:pytest]
minversion = 6.0
addopts = 
    -ra
    -q
    --strict-markers
    --strict-config
    --cov=app
    --cov-report=html
    --cov-report=term-missing:skip-covered
    --cov-fail-under=80
    --maxfail=5
    --tb=short
    -p no:warnings
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers = 
    slow: marks tests as slow (deselect with '-m "not slow"')
    unit: unit tests (fast, isolated)
    integration: integration tests (DB, Redis, API)
    e2e: end-to-end tests (browser-based)
    arabic: tests specific to Arabic text processing
    prosody: prosody engine tests
    performance: performance regression tests
    security: security-focused tests

# Coverage configuration
[coverage:run]
source = app
omit = 
    */tests/*
    */migrations/*
    */__pycache__/*
    */venv/*

[coverage:report]
precision = 2
show_missing = True
skip_covered = False

# Exclude from coverage
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod
```

### Unit Testing Framework

```python
# tests/conftest.py
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.main import app
from app.db.session import get_db
from app.models.base import Base

# Test database
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

@pytest.fixture(scope="session")
def test_db():
    """Create test database"""
    Base.metadata.create_all(bind=engine)
    yield
    Base.metadata.drop_all(bind=engine)

@pytest.fixture
def db_session(test_db):
    """Create database session for testing"""
    session = TestingSessionLocal()
    try:
        yield session
    finally:
        session.close()

@pytest.fixture
def client(db_session):
    """Create test client with database override"""
    def override_get_db():
        try:
            yield db_session
        finally:
            pass
    
    app.dependency_overrides[get_db] = override_get_db
    yield TestClient(app)
    app.dependency_overrides.clear()

@pytest.fixture
def sample_arabic_text():
    """Sample Arabic poetry for testing"""
    return {
        "correct_meter": "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„",
        "incorrect_meter": "Ù‡Ø°Ø§ Ù†Øµ Ø¹Ø§Ø¯ÙŠ Ù„ÙŠØ³ Ø´Ø¹Ø±Ø§Ù‹",
        "mixed_diacritics": "Ù‚ÙÙÙØ§ Ù†ÙØ¨Ù’ÙƒÙ Ù…ÙÙ†Ù’ Ø°ÙÙƒÙ’Ø±ÙÙ‰ Ø­ÙØ¨ÙÙŠØ¨Ù ÙˆÙÙ…ÙÙ†Ù’Ø²ÙÙ„Ù"
    }

@pytest.fixture
def authenticated_user(client, db_session):
    """Create authenticated test user"""
    user_data = {
        "username": "testpoet",
        "email": "poet@test.com", 
        "password": "testpassword123",
        "full_name": "Test Poet"
    }
    
    # Register user
    response = client.post("/api/v1/auth/register", json=user_data)
    assert response.status_code == 201
    
    # Login and get token
    login_data = {"email": user_data["email"], "password": user_data["password"]}
    response = client.post("/api/v1/auth/login", json=login_data)
    token_data = response.json()
    
    # Set authorization header
    client.headers.update({"Authorization": f"Bearer {token_data['access_token']}"})
    
    return {
        "client": client,
        "user_data": user_data,
        "token": token_data["access_token"]
    }
```

### Test Examples

```python
# tests/test_prosody/test_analyzer.py
import pytest
from app.core.prosody.analyzer import ProsodyAnalyzer
from app.core.prosody.normalizer import ArabicNormalizer

class TestProsodyAnalyzer:
    """Test suite for prosody analysis engine"""
    
    @pytest.fixture
    def analyzer(self):
        return ProsodyAnalyzer()
    
    @pytest.fixture 
    def normalizer(self):
        return ArabicNormalizer()
    
    @pytest.mark.unit
    def test_text_normalization(self, normalizer):
        """Test Arabic text normalization"""
        text_with_diacritics = "Ù‚ÙÙÙØ§ Ù†ÙØ¨Ù’ÙƒÙ Ù…ÙÙ†Ù’ Ø°ÙÙƒÙ’Ø±ÙÙ‰ Ø­ÙØ¨ÙÙŠØ¨Ù"
        expected = "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨"
        
        result = normalizer.normalize(text_with_diacritics)
        assert result == expected
    
    @pytest.mark.unit
    def test_syllable_segmentation(self, analyzer):
        """Test syllable segmentation accuracy"""
        text = "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„"
        
        result = analyzer.segment_syllables(text)
        
        assert isinstance(result, list)
        assert len(result) > 0
        assert all(isinstance(syllable, str) for syllable in result)
    
    @pytest.mark.unit
    @pytest.mark.arabic
    def test_meter_detection_taweel(self, analyzer):
        """Test detection of Ø§Ù„Ø·ÙˆÙŠÙ„ meter"""
        verse = "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„"
        
        result = analyzer.detect_meter(verse)
        
        assert result["detected_meter"] == "Ø§Ù„Ø·ÙˆÙŠÙ„"
        assert result["confidence"] > 0.8
    
    @pytest.mark.unit
    def test_quality_scoring(self, analyzer):
        """Test verse quality scoring"""
        good_verse = "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„"
        poor_verse = "Ù‡Ø°Ø§ Ù†Øµ Ø¹Ø§Ø¯ÙŠ ØºÙŠØ± Ø´Ø¹Ø±ÙŠ"
        
        good_score = analyzer.calculate_quality(good_verse)
        poor_score = analyzer.calculate_quality(poor_verse)
        
        assert good_score > poor_score
        assert 0 <= good_score <= 1
        assert 0 <= poor_score <= 1

# tests/test_api/test_analysis.py
import pytest
from fastapi import status

class TestAnalysisAPI:
    """Test suite for analysis API endpoints"""
    
    @pytest.mark.integration
    def test_analyze_poetry_success(self, client, sample_arabic_text):
        """Test successful poetry analysis"""
        request_data = {
            "text": sample_arabic_text["correct_meter"],
            "options": {
                "analysis_mode": "accurate",
                "return_alternatives": True
            }
        }
        
        response = client.post("/api/v1/analyze/", json=request_data)
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        
        assert data["success"] is True
        assert "data" in data
        
        result = data["data"]
        assert "prosodic_analysis" in result
        assert "meter_detection" in result
        assert "quality_score" in result
        assert isinstance(result["processing_time_ms"], int)
    
    @pytest.mark.integration
    def test_analysis_with_authentication(self, authenticated_user, sample_arabic_text):
        """Test analysis with authenticated user"""
        client = authenticated_user["client"]
        
        request_data = {
            "text": sample_arabic_text["correct_meter"],
            "options": {"analysis_mode": "detailed"}
        }
        
        response = client.post("/api/v1/analyze/", json=request_data)
        
        assert response.status_code == status.HTTP_200_OK
        
        # Check that analysis is saved to history
        history_response = client.get("/api/v1/analyze/history")
        assert history_response.status_code == status.HTTP_200_OK
        
        history_data = history_response.json()
        assert len(history_data["data"]) > 0
    
    @pytest.mark.integration  
    def test_batch_analysis(self, client, sample_arabic_text):
        """Test batch analysis endpoint"""
        request_data = {
            "texts": [
                sample_arabic_text["correct_meter"],
                "Ø£Ù„Ø§ ÙÙŠ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø¬Ø¯ Ù…Ø§ Ø£Ù†Ø§ ÙØ§Ø¹Ù„"
            ],
            "analysis_options": {"analysis_mode": "fast"}
        }
        
        response = client.post("/api/v1/analyze/batch", json=request_data)
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        
        assert len(data) == 2
        assert all(result["success"] for result in data)
    
    @pytest.mark.integration
    def test_invalid_text_analysis(self, client):
        """Test analysis with invalid text"""
        request_data = {
            "text": "",  # Empty text
            "options": {}
        }
        
        response = client.post("/api/v1/analyze/", json=request_data)
        
        assert response.status_code == status.HTTP_422_UNPROCESSABLE_ENTITY

# tests/test_e2e/test_user_journey.py
import pytest
from playwright.sync_api import Page, expect

@pytest.mark.e2e
class TestUserJourney:
    """End-to-end user journey tests"""
    
    def test_complete_user_registration_and_analysis(self, page: Page):
        """Test complete user journey from registration to analysis"""
        # Navigate to homepage
        page.goto("http://localhost:3000")
        
        # Register new user
        page.click("text=ØªØ³Ø¬ÙŠÙ„ Ø­Ø³Ø§Ø¨ Ø¬Ø¯ÙŠØ¯")
        page.fill('[data-testid="username"]', "testuser123")
        page.fill('[data-testid="email"]', "testuser@example.com")
        page.fill('[data-testid="password"]', "testpass123")
        page.fill('[data-testid="full-name"]', "Test User")
        page.click('[data-testid="register-button"]')
        
        # Verify successful registration
        expect(page.locator("text=ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ù†Ø¬Ø§Ø­")).to_be_visible()
        
        # Login
        page.fill('[data-testid="login-email"]', "testuser@example.com")
        page.fill('[data-testid="login-password"]', "testpass123")
        page.click('[data-testid="login-button"]')
        
        # Verify successful login
        expect(page.locator("text=Ù…Ø±Ø­Ø¨Ø§Ù‹ Test User")).to_be_visible()
        
        # Navigate to analysis page
        page.click("text=ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ")
        
        # Perform poetry analysis
        page.fill('[data-testid="poem-text"]', "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„")
        page.click('[data-testid="analyze-button"]')
        
        # Verify analysis results
        expect(page.locator('[data-testid="analysis-result"]')).to_be_visible()
        expect(page.locator("text=Ø§Ù„Ø·ÙˆÙŠÙ„")).to_be_visible()
        expect(page.locator('[data-testid="quality-score"]')).to_be_visible()
        
        # Save to history
        page.click('[data-testid="save-analysis"]')
        expect(page.locator("text=ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„")).to_be_visible()
        
        # Check analysis history
        page.click("text=Ø§Ù„Ø³Ø¬Ù„")
        expect(page.locator('[data-testid="analysis-history"]')).to_be_visible()
        expect(page.locator("text=Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰")).to_be_visible()
```

---

## ğŸš€ CI/CD Pipeline

### GitHub Actions Configuration

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  release:
    types: [ published ]

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"

jobs:
  # Backend Tests
  backend-tests:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: bahr_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        cd backend
        pip install -r requirements/testing.txt
    
    - name: Run linting
      run: |
        cd backend
        black --check .
        flake8 .
        mypy app/
    
    - name: Run security checks
      run: |
        cd backend
        bandit -r app/
        safety check
    
    - name: Run unit tests
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/bahr_test
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key
      run: |
        cd backend
        pytest tests/ -v --cov=app --cov-report=xml
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage
  
  # Frontend Tests  
  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      run: |
        cd frontend
        npm ci
    
    - name: Run linting
      run: |
        cd frontend
        npm run lint
    
    - name: Run type checking
      run: |
        cd frontend
        npm run type-check
    
    - name: Run unit tests
      run: |
        cd frontend
        npm run test:coverage
    
    - name: Build application
      run: |
        cd frontend
        npm run build
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        directory: ./frontend/coverage
        flags: frontend
        name: frontend-coverage

  # E2E Tests
  e2e-tests:
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Compose
      run: |
        docker-compose -f docker-compose.test.yml up -d
        sleep 30  # Wait for services to be ready
    
    - name: Run E2E tests
      run: |
        npm install -g @playwright/test
        playwright install
        npm run test:e2e
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: test-results/
    
    - name: Cleanup
      if: always()
      run: docker-compose -f docker-compose.test.yml down

  # Security Scanning
  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # Deploy to Staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, security-scan]
    if: github.ref == 'refs/heads/develop'
    
    environment:
      name: staging
      url: https://staging.bahr.app
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Login to Amazon ECR
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build and push Docker images
      run: |
        # Build backend image
        docker build -t $ECR_REGISTRY/bahr-backend:staging ./backend
        docker push $ECR_REGISTRY/bahr-backend:staging
        
        # Build frontend image  
        docker build -t $ECR_REGISTRY/bahr-frontend:staging ./frontend
        docker push $ECR_REGISTRY/bahr-frontend:staging
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
    
    - name: Deploy to ECS
      run: |
        aws ecs update-service \
          --cluster bahr-staging \
          --service bahr-backend-staging \
          --force-new-deployment
        
        aws ecs update-service \
          --cluster bahr-staging \
          --service bahr-frontend-staging \
          --force-new-deployment
    
    - name: Verify deployment
      run: |
        echo "Waiting for deployment to complete..."
        sleep 60
        
        # Check health endpoints
        curl -f https://staging-api.bahr.app/api/v1/health/ || exit 1
        curl -f https://staging.bahr.app/ || exit 1

  # Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [e2e-tests]
    if: github.event_name == 'release'
    
    environment:
      name: production
      url: https://bahr.app
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Deploy with Blue/Green strategy
      run: |
        # Deploy backend
        aws ecs update-service \
          --cluster bahr-production \
          --service bahr-backend-production \
          --force-new-deployment
        
        # Wait and verify backend health
        sleep 120
        curl -f https://api.bahr.app/api/v1/health/ || exit 1
        
        # Deploy frontend
        aws ecs update-service \
          --cluster bahr-production \
          --service bahr-frontend-production \
          --force-new-deployment
        
        # Final verification
        sleep 60
        curl -f https://bahr.app/ || exit 1
    
    - name: Post-deployment smoke tests
      run: |
        # Run critical path smoke tests
        curl -f https://api.bahr.app/api/v1/health/detailed || exit 1
        
        # Test key API endpoints
        curl -f -X POST https://api.bahr.app/api/v1/analyze/ \
          -H "Content-Type: application/json" \
          -d '{"text": "Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰ Ø­Ø¨ÙŠØ¨ ÙˆÙ…Ù†Ø²Ù„"}' || exit 1
    
    - name: Notify team
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        text: |
          Production deployment ${{ job.status }}!
          Version: ${{ github.event.release.tag_name }}
          URL: https://bahr.app
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-merge-conflict
      - id: check-yaml
      - id: check-json
      - id: check-toml
      - id: check-added-large-files
      - id: check-case-conflict
      
  # Backend (Python)
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        files: ^backend/
        language_version: python3.11
        
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        files: ^backend/
        args: ["--profile", "black"]
        
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        files: ^backend/
        additional_dependencies: [flake8-docstrings]
        
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.3.0
    hooks:
      - id: mypy
        files: ^backend/app/
        additional_dependencies: [types-all]
        
  # Frontend (Node.js)
  - repo: https://github.com/pre-commit/mirrors-eslint
    rev: v8.44.0
    hooks:
      - id: eslint
        files: ^frontend/
        additional_dependencies:
          - eslint@8.44.0
          - "@typescript-eslint/eslint-plugin@5.60.0"
          - "@typescript-eslint/parser@5.60.0"
          
  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v3.0.0
    hooks:
      - id: prettier
        files: ^frontend/
        exclude: ^frontend/node_modules/
        
  # Security
  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.5
    hooks:
      - id: bandit
        files: ^backend/
        args: ["-c", "backend/pyproject.toml"]
        
  # Documentation
  - repo: https://github.com/executablebooks/mdformat
    rev: 0.7.16
    hooks:
      - id: mdformat
        additional_dependencies:
          - mdformat-gfm
          - mdformat-black
```

---

## ğŸ“¦ Deployment Strategies

### Docker Configuration

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV POETRY_NO_INTERACTION=1
ENV POETRY_VENV_IN_PROJECT=1
ENV POETRY_CACHE_DIR=/opt/poetry_cache

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install poetry

# Set work directory
WORKDIR /app

# Copy poetry files
COPY pyproject.toml poetry.lock ./

# Install dependencies
RUN poetry install --only=main && rm -rf $POETRY_CACHE_DIR

# Copy application code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash app && chown -R app:app /app
USER app

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:8000/api/v1/health/ || exit 1

# Run application
CMD ["poetry", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build application
RUN npm run build

# Production stage
FROM nginx:alpine

# Copy built application
COPY --from=builder /app/dist /usr/share/nginx/html

# Copy Nginx configuration
COPY nginx.conf /etc/nginx/nginx.conf

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=30s --retries=3 \
    CMD curl -f http://localhost/ || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Database
  postgres:
    image: postgres:15
    container_name: bahr-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    
  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: bahr-redis
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    
  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: bahr-backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
    volumes:
      - ./backend/logs:/app/logs
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health/"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    
  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: bahr-frontend
    depends_on:
      backend:
        condition: service_healthy
    ports:
      - "3000:80"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    
  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    container_name: bahr-nginx
    depends_on:
      - frontend
      - backend
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    ports:
      - "80:80"
      - "443:443"
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

---

## ğŸ” Monitoring & Logging

### Application Monitoring

```python
# app/core/monitoring.py
import time
import logging
from contextlib import contextmanager
from functools import wraps
from typing import Dict, Any, Optional
import structlog
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# Metrics
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')
ACTIVE_USERS = Gauge('active_users_total', 'Number of active users')
ANALYSIS_COUNT = Counter('poetry_analyses_total', 'Total poetry analyses', ['meter', 'status'])

# Structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer(ensure_ascii=False)
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

@contextmanager
def monitor_analysis_performance(meter_name: Optional[str] = None):
    """Context manager to monitor analysis performance"""
    start_time = time.time()
    try:
        yield
        duration = time.time() - start_time
        ANALYSIS_COUNT.labels(meter=meter_name or "unknown", status="success").inc()
        logger.info("Analysis completed", duration=duration, meter=meter_name)
    except Exception as e:
        duration = time.time() - start_time
        ANALYSIS_COUNT.labels(meter=meter_name or "unknown", status="error").inc()
        logger.error("Analysis failed", duration=duration, meter=meter_name, error=str(e))
        raise

def monitor_endpoint(func):
    """Decorator to monitor API endpoint performance"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(
                method="POST",  # Assuming POST for simplicity
                endpoint=func.__name__,
                status="success"
            ).inc()
            REQUEST_DURATION.observe(time.time() - start_time)
            return result
        except Exception as e:
            REQUEST_COUNT.labels(
                method="POST",
                endpoint=func.__name__,
                status="error"
            ).inc()
            logger.error("Endpoint error", endpoint=func.__name__, error=str(e))
            raise
    return wrapper

# Start metrics server
def start_metrics_server(port: int = 9090):
    """Start Prometheus metrics server"""
    start_http_server(port)
    logger.info("Metrics server started", port=port)
```

### Error Tracking

```python
# app/core/error_tracking.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration
from app.config import settings

def setup_error_tracking():
    """Configure Sentry for error tracking"""
    if settings.SENTRY_DSN:
        sentry_sdk.init(
            dsn=settings.SENTRY_DSN,
            integrations=[
                FastApiIntegration(auto_enabling_integrations=False),
                SqlalchemyIntegration(),
            ],
            traces_sample_rate=0.1,
            environment=settings.ENVIRONMENT,
            release=settings.VERSION,
            before_send=filter_sensitive_data
        )

def filter_sensitive_data(event, hint):
    """Filter sensitive data from error reports"""
    # Remove sensitive headers
    if 'request' in event:
        headers = event['request'].get('headers', {})
        headers.pop('authorization', None)
        headers.pop('cookie', None)
    
    # Remove sensitive form data
    if 'request' in event and 'data' in event['request']:
        data = event['request']['data']
        if isinstance(data, dict):
            data.pop('password', None)
            data.pop('token', None)
    
    return event
```

---

## ğŸ”’ Security Best Practices

### Security Configuration

```python
# app/core/security_config.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.httpsredirect import HTTPSRedirectMiddleware
import secrets

def configure_security(app: FastAPI):
    """Configure security middleware and settings"""
    
    # HTTPS redirect in production
    if not settings.DEBUG:
        app.add_middleware(HTTPSRedirectMiddleware)
    
    # Trusted host protection
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=["*.bahr.app", "bahr.app", "localhost", "127.0.0.1"]
    )
    
    # CORS configuration
    app.add_middleware(
        CORSMiddleware,
        allow_origins=settings.ALLOWED_ORIGINS,
        allow_credentials=True,
        allow_methods=["GET", "POST", "PUT", "DELETE"],
        allow_headers=["*"],
        expose_headers=["X-Process-Time"]
    )
    
    # Security headers
    @app.middleware("http")
    async def add_security_headers(request, call_next):
        response = await call_next(request)
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "script-src 'self' 'unsafe-inline' 'unsafe-eval'; "
            "style-src 'self' 'unsafe-inline'; "
            "img-src 'self' data: https:; "
            "font-src 'self' https://fonts.googleapis.com https://fonts.gstatic.com;"
        )
        return response

# Secrets management
class SecretManager:
    """Secure secrets management"""
    
    @staticmethod
    def generate_secret_key() -> str:
        """Generate cryptographically secure secret key"""
        return secrets.token_urlsafe(32)
    
    @staticmethod
    def hash_api_key(api_key: str) -> str:
        """Hash API key for secure storage"""
        import hashlib
        return hashlib.sha256(api_key.encode()).hexdigest()

---

## ğŸ›¡ï¸ Ù‚Ø§Ø¦Ù…Ø© Ø£Ù…Ø§Ù† Ø§Ù„Ù€ MVP (MVP Security Checklist)

Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØªÙÙ†ÙÙ‘ÙØ° ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ø¨Ø¯Ø¡Ø§Ù‹ Ù…Ù† Week 1 ÙˆØªÙƒØªÙ…Ù„ Ù‚Ø¨Ù„ Ù†Ù‡Ø§ÙŠØ© Week 4.

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1 (Week 1-2): Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª
- [ ] ØªÙØ¹ÙŠÙ„ CORS Ù…Ø¹ origins Ù…Ø­Ø¯Ø¯Ø© (localhost + Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ù„Ø§Ø­Ù‚Ø§Ù‹)
- [ ] Ø¥Ø¶Ø§ÙØ© Security Headers (Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `security_config.py`) ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª.
- [ ] ØªÙˆÙ„ÙŠØ¯ SECRET_KEY Ù‚ÙˆÙŠ (32+ bytes) ÙˆØ¹Ø¯Ù… ØªØ®Ø²ÙŠÙ†Ù‡ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹.
- [ ] ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ø¬Ø³Ù… (Body) Ù„Ù„Ø·Ù„Ø¨ `/analyze` (100KB) Ø¹Ø¨Ø± middleware (Ø±Ø§Ø¬Ø¹ `BACKEND_API.md`).
- [ ] Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª (Rate limiting) Ù„ÙƒÙ„ IP (100 Ø·Ù„Ø¨/Ø³Ø§Ø¹Ø©) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Redis.
- [ ] ØªÙ…ÙŠÙŠØ² Ø¬Ù…ÙŠØ¹ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ 5xx Ø¨Ø­Ù‚Ù„ `request_id`.
- [ ] ØªØ¹Ø·ÙŠÙ„ Ø£Ùˆ Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ø¬Ù‡Ø© Swagger ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (`/docs`).

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2 (Week 3-4): Ø§Ù„ØªØ¹Ø²ÙŠØ²
- [ ] ØªÙØ¹ÙŠÙ„ Ù†Ø¸Ø§Ù… Token Refresh (Ø¹Ù…Ø± ÙˆØµÙˆÙ„ Ù‚ØµÙŠØ± + Refresh Ø£Ø·ÙˆÙ„).
- [ ] Ø¥Ø¶Ø§ÙØ© ÙØ­Øµ Ø¨Ø³ÙŠØ· Ù„Ù€ API Key Ø¯Ø§Ø®Ù„ÙŠ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ© (ingestion).
- [ ] Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø¹Ø¯Ù„ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„ÙØ§Ø´Ù„Ø© (Counter + Alert > 20/10m).
- [ ] Ø¯Ù…Ø¬ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙØ´Ù„ Ù…ØªÙƒØ±Ø± (5xx spike / rate limit abuse) ÙÙŠ Grafana.

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3 (Pre-Launch): Ø§Ù„ØµÙ„Ø§Ø¨Ø©
- [ ] ÙØ­Øµ Ø«ØºØ±Ø§Øª Ø§Ù„Ø­Ø²Ù… (pip audit / npm audit) Ø¨Ø¯ÙˆÙ† ØªØ­Ø°ÙŠØ±Ø§Øª Ø­Ø±Ø¬Ø©.
- [ ] Ù…Ø±Ø§Ø¬Ø¹Ø© ÙŠØ¯ÙˆÙŠØ© Ù„Ù€ 10 Ù…Ù„ÙØ§Øª Ø­Ø³Ø§Ø³Ø© (auth, security, rate limiting, error handling).
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø®ØªØ±Ø§Ù‚ Ø¯Ø§Ø®Ù„ÙŠ (Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª: XSSØŒ SQLiØŒ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…Ø¹Ø¯Ù„ØŒ Ø±ÙØ¹ Ø§Ù„Ø­Ø¬Ù…).

Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù‚Ø¨ÙˆÙ„ Ù„Ù„Ø£Ù…Ø§Ù† (MVP):
```yaml
No critical dependency vulnerabilities: true
Unauthorized meter access possible: false
Rate-limit bypass attempts logged & alerted: true
Leak of secrets in logs: false
Open API docs publicly in production: false
```

---

## ğŸ§ª Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Minimum Viable Tests)

ÙŠØ¬Ø¨ ØªÙˆÙØ± Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù‚Ø¨Ù„ Ø¯Ù…Ø¬ Ø£ÙˆÙ„ Ø¥ØµØ¯Ø§Ø± Ù„Ù„Ù…Ø­Ø±Ùƒ (Week 3) Ù„Ø¶Ù…Ø§Ù† Ø¨Ù†Ø§Ø¡ Ù…Ø³ØªÙ‚Ø±.

### Backend Minimum
- [ ] 12 Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ­Ø¯Ø© Ù„Ù„ØªØ·Ø¨ÙŠØ¹ (diacriticsØŒ shaddaØŒ tanwÄ«nØŒ hamza).
- [ ] 8 Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ­Ø¯Ø© Ù„Ù„ØªÙ‚Ø·ÙŠØ¹ (syllable boundaries Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© + madd).
- [ ] 16 Ø§Ø®ØªØ¨Ø§Ø± Meter (1 Ù…Ø«Ø§Ù„ Ù„ÙƒÙ„ Ø¨Ø­Ø± ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ).
- [ ] 4 Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª API (ØªØ­Ù„ÙŠÙ„ Ù†Ø§Ø¬Ø­ØŒ ØªØ­Ù„ÙŠÙ„ ÙØ´Ù„ ØªØ­Ù‚Ù‚ØŒ Ù…Ø¹Ø¯Ù„ Ø·Ù„Ø¨Ø§ØªØŒ Ø­Ø¬Ù… Ø²Ø§Ø¦Ø¯).
- [ ] 2 Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ù…Ø¨Ø³Ø· (Ø²Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØª ÙˆØ§Ø­Ø¯ < 500msØŒ Ø¯ÙØ¹Ø© 5 Ø£Ø¨ÙŠØ§Øª < 2.5s).
- [ ] 4 Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø£Ù…Ù† (Ù…Ø­Ø§ÙˆÙ„Ø© XSSØŒ Ø­Ø¬Ù… Ø²Ø§Ø¦Ø¯ØŒ ØªØ¬Ø§ÙˆØ² Ù…Ø¹Ø¯Ù„ØŒ Ù†Øµ ÙØ§Ø±Øº).

### Frontend Minimum
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ (RTL + Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø­Ø±ÙˆÙ).
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø¨Ø¯Ø§Ø¦Ù„ meter.
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ / Ø®Ø·Ø£.
- [ ] Ø§Ø®ØªØ¨Ø§Ø± hook `useAnalyze` (Ù†Ø¬Ø§Ø­ + Ø®Ø·Ø£ + Ø¥Ø¹Ø§Ø¯Ø© Ø·Ù„Ø¨).

### CI Minimum Gates
```yaml
coverage: >= 40% (ÙŠØ±ØªÙØ¹ ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹ Ø¥Ù„Ù‰ 80%)
lint: pass (no error severity findings)
security scan: no critical issues
tests: required (unit + minimal integration)
build: green (frontend + backend docker build)
```

### ØªØµØ¹ÙŠØ¯ Ø§Ù„ØªØºØ·ÙŠØ© (Coverage Ramp)
```yaml
Week 3: 40%
Week 5: 55%
Week 7: 65%
Week 10: 75%
Week 12: 80% (Beta)
Week 13: 80% (Launch)
```

Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£Ø¹Ù„Ù‰ (95% Ù„Ø¨Ø¹Ø¶ Ø§Ù„ÙˆØ­Ø¯Ø§Øª) ÙŠØ¨Ù‚Ù‰ ÙÙŠ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ø£Ø¹Ù„Ø§Ù‡ØŒ Ù„ÙƒÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¯Ù†ÙŠØ§ ØªÙ…Ù†Ø¹ Ø§Ù„ØªØ¯Ù‡ÙˆØ±.

---
```

---

## ğŸ“Š Performance Optimization

### Database Query Optimization

```python
# app/db/optimization.py
from sqlalchemy import text
from sqlalchemy.orm import Session
import asyncio
from typing import List, Dict, Any

class QueryOptimizer:
    """Database query optimization utilities"""
    
    @staticmethod
    def explain_query(db: Session, query: str) -> Dict[str, Any]:
        """Analyze query execution plan"""
        explain_query = text(f"EXPLAIN ANALYZE {query}")
        result = db.execute(explain_query).fetchall()
        return {
            "execution_plan": [dict(row) for row in result],
            "optimization_suggestions": QueryOptimizer._analyze_plan(result)
        }
    
    @staticmethod
    def _analyze_plan(execution_plan) -> List[str]:
        """Analyze execution plan and provide optimization suggestions"""
        suggestions = []
        
        for row in execution_plan:
            plan_text = str(row[0])
            
            if "Seq Scan" in plan_text:
                suggestions.append("Consider adding an index for sequential scan")
            
            if "cost=" in plan_text and "rows=" in plan_text:
                # Extract cost and rows information
                import re
                cost_match = re.search(r'cost=([\d.]+)\.\.([\d.]+)', plan_text)
                if cost_match and float(cost_match.group(2)) > 1000:
                    suggestions.append("High cost operation detected - consider query optimization")
        
        return suggestions

# Connection pooling optimization
from sqlalchemy.pool import QueuePool

def create_optimized_engine():
    """Create database engine with optimized settings"""
    return create_engine(
        settings.DATABASE_URL,
        poolclass=QueuePool,
        pool_size=20,
        max_overflow=30,
        pool_pre_ping=True,
        pool_recycle=3600,
        echo=settings.DEBUG
    )
```

### Caching Strategy

```python
# app/core/cache_strategy.py
import redis
import json
import pickle
from typing import Any, Optional, Union
from functools import wraps
import hashlib

class CacheManager:
    """Advanced caching with multiple strategies"""
    
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
        self.default_ttl = 3600  # 1 hour
    
    def cache_key(self, prefix: str, *args, **kwargs) -> str:
        """Generate consistent cache key"""
        key_data = f"{prefix}:{args}:{sorted(kwargs.items())}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    async def get(self, key: str) -> Optional[Any]:
        """Get value from cache"""
        try:
            data = self.redis.get(key)
            if data:
                return pickle.loads(data)
            return None
        except Exception:
            return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """Set value in cache"""
        try:
            serialized = pickle.dumps(value)
            self.redis.setex(key, ttl or self.default_ttl, serialized)
        except Exception:
            pass  # Fail silently for cache errors
    
    async def delete(self, pattern: str) -> None:
        """Delete keys matching pattern"""
        keys = self.redis.keys(pattern)
        if keys:
            self.redis.delete(*keys)
    
    def cached(self, ttl: int = 3600, key_prefix: str = ""):
        """Decorator for caching function results"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                cache_key = self.cache_key(key_prefix or func.__name__, *args, **kwargs)
                
                # Try to get from cache
                cached_result = await self.get(cache_key)
                if cached_result is not None:
                    return cached_result
                
                # Execute function and cache result
                result = await func(*args, **kwargs)
                await self.set(cache_key, result, ttl)
                return result
            
            return wrapper
        return decorator

# Usage example
cache_manager = CacheManager(settings.REDIS_URL)

@cache_manager.cached(ttl=1800, key_prefix="analysis")
async def cached_analysis(text: str, options: dict):
    """Cached poetry analysis"""
    # Expensive analysis operation
    return perform_analysis(text, options)
```

---

## ğŸ¯ Next Steps

âœ… **Development Workflow Guide Ù…ÙƒØªÙ…Ù„**

Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ ÙÙŠ Ø§Ù„ØªÙˆØ«ÙŠÙ‚:
1. **[Arabic NLP Research](../research/ARABIC_NLP_RESEARCH.md)** - Ù…Ø±Ø§Ø¬Ø¹ ÙˆÙ…ÙƒØªØ¨Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
2. **[Project Timeline](../planning/PROJECT_TIMELINE.md)** - Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø±Ø§Ø­Ù„

---

## ğŸ“ Ù…Ù„Ø®Øµ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„

### ğŸ› ï¸ Development Excellence:
- **Git Flow** Ù…Ù†Ø¸Ù… Ù…Ø¹ branch protection
- **Code Quality** Ù…Ø¹ pre-commit hooks
- **Testing Pyramid** Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ØªØ¯Ø±Ø¬Ø©
- **CI/CD Pipeline** Ù…Ø¤ØªÙ…Øª Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
- **Security** Ù…Ø¯Ù…Ø¬Ø© ÙÙŠ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø©

### ğŸš€ Deployment Ready:
- **Docker** containerization ÙƒØ§Ù…Ù„Ø©
- **Multi-environment** staging + production
- **Health checks** Ùˆmonitoring Ø´Ø§Ù…Ù„
- **Blue/Green deployment** Ù„Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¢Ù…Ù†
- **Error tracking** Ù…Ø¹ Sentry

### ğŸ“Š Quality Assurance:
- **80%+ test coverage** Ù…Ø·Ù„ÙˆØ¨
- **Security scanning** ØªÙ„Ù‚Ø§Ø¦ÙŠ
- **Performance monitoring** Ù…Ø³ØªÙ…Ø±
- **Code review** Ø¥Ø¬Ø¨Ø§Ø±ÙŠ
- **Documentation** Ù…Ø¹ ÙƒÙ„ feature

---

**âš™ï¸ Ù‡Ø°Ø§ ÙŠÙƒÙ…Ù„ Ø¯Ù„ÙŠÙ„ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± - Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©!**