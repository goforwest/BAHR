# ğŸš€ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù†Ø´Ø± (Deployment Guide)
## Ø¥Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù†Ø´Ø± Ù…Ù†ØµØ© Ø¨ÙØ­Ù’Ø± - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø£ÙˆÙ„ (MVP)

---

## ğŸ¯ Ø§Ù„Ù‡Ø¯Ù
ØªÙˆÙÙŠØ± Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ° Ù„Ù†Ø´Ø± Ø§Ù„Ù…Ù†ØµØ© (Backend + Frontend + DB + Ù…Ø±Ø§Ù‚Ø¨Ø©) ÙÙŠ Ø¨ÙŠØ¦Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø«Ù… Ø¥Ù†ØªØ§Ø¬ÙŠØ©ØŒ Ù…Ø¹ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù…Ù† Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ ÙˆØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªÙˆØ³Ø¹ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ.

---

## ğŸ§± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù†Ø´Ø±
- Backend (FastAPI) Ø­Ø§ÙˆÙŠØ© Docker
- Frontend (Next.js) Ø­Ø§ÙˆÙŠØ© Docker (Ø¨Ù†Ø§Ø¡ static Ø£Ùˆ ØªØ´ØºÙŠÙ„ Node Ø­Ø³Ø¨ Ø§Ù„Ù…Ø±Ø­Ù„Ø©)
- PostgreSQL Ù…ÙØ¯Ø§Ø±Ø© (ÙŠÙØ¶Ù„ Cloud: Supabase / RDS / Neon) Ø£Ùˆ Ø­Ø§ÙˆÙŠØ© Ù…Ø¨Ø¯Ø¦ÙŠØ©
- Redis (Caching + Rate Limiting) â€“ Ø­Ø§ÙˆÙŠØ© Ø£Ùˆ Ø®Ø¯Ù…Ø© Ù…ÙØ¯Ø§Ø±Ø©
- Ù…Ø±Ø§Ù‚Ø¨Ø©: Prometheus + Grafana (Week 2+)
- Ø£Ø®Ø·Ø§Ø¡: Sentry (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ø§Ø­Ù‚Ø§Ù‹)

---

## ğŸ¢ Ù‚Ø±Ø§Ø± Ø§Ø³ØªØ¶Ø§ÙØ© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (Production Hosting Decision)

### Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ¶Ø§ÙØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:

#### **Option 1: Railway (Ù…ÙˆØµÙ‰ Ø¨Ù‡ Ù„Ù„MVP) ğŸ’š**
```yaml
Pros:
  - Ù†Ø´Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù…Ù† Git
  - PostgreSQL + Redis Ù…Ø¯Ù…Ø¬Ø©
  - ØªØ³Ø¹ÙŠØ± Ø¨Ø³ÙŠØ· ($5-20/month Ù„Ù„MVP)
  - Ø¯Ø¹Ù… Docker native
  - SSL Ù…Ø¬Ø§Ù†ÙŠ + Domain
Cons:
  - Ù…Ø­Ø¯ÙˆØ¯ÙŠØ© Ø§Ù„ØªØ®ØµÙŠØµ
  - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ÙƒÙ„ÙÙ‹Ø§ Ù…Ø¹ Ø§Ù„Ù†Ù…Ùˆ
Use Case: MVP + Beta (Week 1-12)
```

#### **Option 2: DigitalOcean App Platform**
```yaml
Pros:
  - Ù…Ø±ÙˆÙ†Ø© Ø£Ø¹Ù„Ù‰ Ù…Ù† Railway
  - ØªØ³Ø¹ÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ($12-30/month)
  - PostgreSQL Managed Database
  - Monitoring Ù…Ø¯Ù…Ø¬
Cons:
  - ØªØ¹Ù‚ÙŠØ¯ Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹
  - Redis ÙŠØ­ØªØ§Ø¬ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù†ÙØµÙ„
Use Case: Post-MVP growth (3-6 months)
```

#### **Option 3: Vercel (Frontend) + Railway (Backend)**
```yaml
Pros:
  - Vercel Ù…Ø«Ø§Ù„ÙŠ Ù„Ù€ Next.js (ØªØ­Ø³ÙŠÙ† ØªÙ„Ù‚Ø§Ø¦ÙŠ)
  - Railway Ù„Ù„Backend + DB
  - Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø² Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
Cons:
  - Ø¥Ø¯Ø§Ø±Ø© Ù…Ù†ØµØªÙŠÙ† Ù…Ù†ÙØµÙ„ØªÙŠÙ†
  - ØªÙƒÙ„ÙØ© Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹
Use Case: Production launch (Week 13+)
```

**Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡:**
- **MVP (Week 1-12):** Railway All-in-One
- **Production (Week 13+):** Migrate to Vercel (Frontend) + DigitalOcean (Backend)

---

## ğŸ—‚ï¸ Ù‡ÙŠÙƒÙ„ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø´Ø± (Ù…Ø­Ø¯Ù‘Ø«)
```
BAHR/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ requirements/
â”‚   â”‚   â”œâ”€â”€ base.txt
â”‚   â”‚   â”œâ”€â”€ production.txt
â”‚   â”‚   â””â”€â”€ development.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ next.config.js
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker-compose.yml          # Ù„Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠ
â”œâ”€â”€ docker-compose.prod.yml     # Ù„Ù„Ø¥Ù†ØªØ§Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
â”œâ”€â”€ .env.example                # Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©
â”œâ”€â”€ railway.json                # ØªÙƒÙˆÙŠÙ† Railway (Ø¥Ù† Ø§Ø³ØªØ®Ø¯Ù…)
â””â”€â”€ scripts/
    â”œâ”€â”€ deploy_dev.sh
    â”œâ”€â”€ deploy_prod.sh
    â”œâ”€â”€ migrate.sh
    â””â”€â”€ backup_db.sh
```

---

## ğŸ³ Dockerfiles (Ø£Ù…Ø«Ù„Ø© Ù…Ø¨Ø³Ø·Ø©)

### Backend (`backend/Dockerfile`)
```dockerfile
# Multi-stage build for production optimization
FROM python:3.11-slim AS base

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install Python dependencies
COPY requirements/base.txt requirements/production.txt ./
RUN pip install -r production.txt

# Copy application code
COPY app/ ./app/
COPY alembic/ ./alembic/
COPY alembic.ini ./

# Create non-root user
RUN useradd -m -u 1000 bahr && chown -R bahr:bahr /app
USER bahr

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/api/v1/health')"

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2"]
```

### Frontend (`frontend/Dockerfile`)
```dockerfile
# Build stage
FROM node:20-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy source code
COPY . .

# Build Next.js app
RUN npm run build

# Production stage
FROM node:20-alpine AS runner

WORKDIR /app

ENV NODE_ENV=production

# Create non-root user
RUN addgroup --system --gid 1001 nodejs && \
    adduser --system --uid 1001 nextjs

# Copy built assets
COPY --from=builder /app/public ./public
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

# Change ownership
RUN chown -R nextjs:nodejs /app

USER nextjs

EXPOSE 3000

ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

CMD ["node", "server.js"]
```

### Docker Compose Ù„Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠ (`docker-compose.yml`)
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: bahr_postgres
    environment:
      POSTGRES_DB: bahr_dev
      POSTGRES_USER: bahr
      POSTGRES_PASSWORD: dev_password_change_me
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U bahr"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: bahr_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: bahr_backend
    environment:
      DATABASE_URL: postgresql://bahr:dev_password_change_me@postgres:5432/bahr_dev
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: dev_secret_key_change_in_production
      DEBUG: "True"
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: builder  # Use builder stage for hot reload
    container_name: bahr_frontend
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8000
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - backend
    command: npm run dev

  prometheus:
    image: prom/prometheus:latest
    container_name: bahr_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  grafana:
    image: grafana/grafana:latest
    container_name: bahr_grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin_change_me
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana-dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

---

## ğŸ”„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ù‡Ø§Ø¬Ø±Ø§Øª (Database Migration Strategy)

### Ø¥Ø¹Ø¯Ø§Ø¯ Alembic (Week 1)
```bash
# ÙÙŠ Ù…Ø¬Ù„Ø¯ backend/
alembic init alembic

# ØªØ­Ø¯ÙŠØ« alembic.ini
# sqlalchemy.url = postgresql://user:pass@localhost/dbname
```

### Ø¥Ù†Ø´Ø§Ø¡ Migration Ø¬Ø¯ÙŠØ¯
```bash
# Ø¨Ø¹Ø¯ ØªØ¹Ø¯ÙŠÙ„ models
alembic revision --autogenerate -m "Add meters table"

# Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙÙ†Ø´Ø£ ÙÙŠ alembic/versions/
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØµØ­ÙŠØ­Ø©!
```

### ØªØ·Ø¨ÙŠÙ‚ Migrations

**Ù…Ø­Ù„ÙŠØ§Ù‹ (Development):**
```bash
# ØªØ·Ø¨ÙŠÙ‚ Ø¢Ø®Ø± migration
alembic upgrade head

# Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø¢Ø®Ø± migration
alembic downgrade -1

# Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Migrations
alembic history
```

**ÙÙŠ Docker:**
```bash
# ØªØ·Ø¨ÙŠÙ‚ migrations Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„Ø­Ø§ÙˆÙŠØ©
docker compose run --rm backend alembic upgrade head

# Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© ÙÙŠ entrypoint.sh
#!/bin/bash
alembic upgrade head
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

**ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (Railway/DigitalOcean):**
```bash
# Option 1: ØªØ´ØºÙŠÙ„ migration ÙƒÙ€ one-off command
railway run alembic upgrade head

# Option 2: ÙÙŠ CI/CD pipeline
# .github/workflows/deploy.yml
- name: Run migrations
  run: |
    alembic upgrade head
  env:
    DATABASE_URL: ${{ secrets.DATABASE_URL }}
```

### Best Practices Ù„Ù„Migrations
```yaml
Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Migration:
  - âœ… Ù‚Ù… Ø¨Ø§Ù„Ù€ backup Ù„Ù„Ù‚Ø§Ø¹Ø¯Ø© Ù‚Ø¨Ù„ ØªØ·Ø¨ÙŠÙ‚ migrations ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬
  - âœ… Ø§Ø®ØªØ¨Ø± Ø§Ù„Ù€ migration Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© staging Ø£ÙˆÙ„Ø§Ù‹
  - âœ… Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù€ SQL Ø§Ù„Ù…ÙÙ†Ø´Ø£ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„!)
  - âœ… Ø£Ø¶Ù default values Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ NOT NULL

ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬:
  - âš ï¸ Ù„Ø§ ØªØ­Ø°Ù Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø© - Ø¹Ù„Ù‘Ù…Ù‡Ø§ deprecated Ø£ÙˆÙ„Ø§Ù‹
  - âš ï¸ Ø§Ø³ØªØ®Ø¯Ù… transactions Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø±Ø¬Ø©
  - âš ï¸ Ø§Ø­ØªÙØ¸ Ø¨Ù†Ø³Ø®Ø© backup Ù‚Ø¨Ù„ ÙƒÙ„ migration
  - âš ï¸ ØªÙˆØ«ÙŠÙ‚ ÙƒÙ„ migration Ø¨ØªØ¹Ù„ÙŠÙ‚ ÙˆØ§Ø¶Ø­
```

### Ù…Ø«Ø§Ù„ Migration Script
```python
# alembic/versions/001_add_meters_table.py
"""Add meters table

Revision ID: 001
Create Date: 2025-11-08
"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ meters
    op.create_table(
        'meters',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(100), nullable=False, unique=True),
        sa.Column('english_name', sa.String(100)),
        sa.Column('base_pattern', sa.Text(), nullable=False),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), server_default=sa.text('now()')),
        sa.PrimaryKeyConstraint('id')
    )
    
    # Ø¥Ù†Ø´Ø§Ø¡ index
    op.create_index('idx_meters_name', 'meters', ['name'])
    
    # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¨Ø­ÙˆØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    op.execute("""
        INSERT INTO meters (name, english_name, base_pattern) VALUES
        ('Ø§Ù„Ø·ÙˆÙŠÙ„', 'At-Taweel', 'ÙØ¹ÙˆÙ„Ù† Ù…ÙØ§Ø¹ÙŠÙ„Ù† ÙØ¹ÙˆÙ„Ù† Ù…ÙØ§Ø¹ÙŠÙ„Ù†'),
        ('Ø§Ù„ÙƒØ§Ù…Ù„', 'Al-Kamil', 'Ù…ØªÙØ§Ø¹Ù„Ù† Ù…ØªÙØ§Ø¹Ù„Ù† Ù…ØªÙØ§Ø¹Ù„Ù†'),
        ('Ø§Ù„ÙˆØ§ÙØ±', 'Al-Wafir', 'Ù…ÙØ§Ø¹Ù„ØªÙ† Ù…ÙØ§Ø¹Ù„ØªÙ† ÙØ¹ÙˆÙ„Ù†');
    """)

def downgrade():
    op.drop_index('idx_meters_name', table_name='meters')
    op.drop_table('meters')
```

---

## ğŸ” Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© (Environment Variables Management)

### Ù…Ù„Ù `.env.example` (Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ†)
```bash
# Application
PROJECT_NAME=BAHR Poetry Analysis Platform
DEBUG=True
SECRET_KEY=your-secret-key-min-32-chars
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000

# Database
DATABASE_URL=postgresql://bahr:password@localhost:5432/bahr_dev
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10

# Redis
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=10

# API
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=3600

# CORS
ALLOWED_ORIGINS=http://localhost:3000

# Email (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=
SMTP_PASSWORD=

# Monitoring
SENTRY_DSN=
LOG_LEVEL=INFO

# External APIs (Phase 2+)
OPENAI_API_KEY=
HUGGINGFACE_TOKEN=
```

### Ø¥Ø¯Ø§Ø±Ø© Secrets ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬

#### Railway
```bash
# Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© Railway Dashboard
# 1. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ Project Settings > Variables
# 2. Ø£Ø¶Ù ÙƒÙ„ Ù…ØªØºÙŠØ± Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„
# 3. Railway ÙŠØ¹ÙŠØ¯ Ø§Ù„Ù†Ø´Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ø§Ù„ØªØºÙŠÙŠØ±

# Ø£Ùˆ Ø¹Ø¨Ø± CLI
railway variables set SECRET_KEY=your-production-secret
railway variables set DATABASE_URL=postgresql://...
```

#### GitHub Actions (Ù„Ù„CI/CD)
```yaml
# .github/workflows/deploy.yml
env:
  DATABASE_URL: ${{ secrets.DATABASE_URL }}
  SECRET_KEY: ${{ secrets.SECRET_KEY }}
  REDIS_URL: ${{ secrets.REDIS_URL }}

# Ø¥Ø¶Ø§ÙØ© Secrets:
# GitHub Repo > Settings > Secrets > Actions > New repository secret
```

#### DigitalOcean App Platform
```bash
# Ø¹Ø¨Ø± doctl CLI
doctl apps create-deployment <app-id> \
  --env "SECRET_KEY=your-secret" \
  --env "DATABASE_URL=postgresql://..."

# Ø£Ùˆ Ø¹Ø¨Ø± Dashboard
# App > Settings > App-Level Environment Variables
```

### Best Practices Ù„Ù„Secrets
```yaml
âœ… DO:
  - Ø§Ø³ØªØ®Ø¯Ù… secrets manager (Railway/GitHub/Vault)
  - Ù‚Ù… Ø¨ØªØ¯ÙˆÙŠØ± SECRET_KEY ÙƒÙ„ 3-6 Ø£Ø´Ù‡Ø±
  - Ø§Ø³ØªØ®Ø¯Ù… DATABASE_URL ÙƒØ§Ù…Ù„Ø© (ØªØªØ¶Ù…Ù† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª)
  - Ø§ÙØµÙ„ Ø¨ÙŠØ¦Ø§Øª dev/staging/production Ø¨Ù€ secrets Ù…Ø®ØªÙ„ÙØ©

âŒ DON'T:
  - Ù„Ø§ ØªØ¶Ø¹ secrets ÙÙŠ Git EVER
  - Ù„Ø§ ØªØ´Ø§Ø±Ùƒ .env files Ø¹Ø¨Ø± email/slack
  - Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… secrets Ø¨Ø³ÙŠØ·Ø© (password123)
  - Ù„Ø§ ØªØ¶Ø¹ API keys ÙÙŠ frontend code
```

### ØªÙˆÙ„ÙŠØ¯ SECRET_KEY Ø¢Ù…Ù†
```python
# ÙÙŠ Python
import secrets
print(secrets.token_urlsafe(32))
# Output: XYZ123ABC...  (Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§)

# Ø£Ùˆ ÙÙŠ terminal
openssl rand -base64 32
```

---

## ğŸš¦ Ø¥Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ
1. Dev: ØªØ´ØºÙŠÙ„ Ù…Ø­Ù„ÙŠ (`docker-compose.dev.yml`)
2. Staging: Ø­Ø§ÙˆÙŠØ§Øª Ø¹Ù„Ù‰ VPS (Ù…Ø«Ù„Ø§Ù‹ Hetzner) Ø£Ùˆ Render
3. Production: Ø®Ø¯Ù…Ø© Ù…ÙØ¯Ø§Ø±Ø© Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + Ø­Ø§ÙˆÙŠØ§Øª Ø«Ø§Ø¨ØªØ© + Ù…Ø±Ø§Ù‚Ø¨Ø©

Rollback (Ù…Ø¨Ø³Ø·):
- Ø§Ø­ØªÙØ¸ Ø¨Ø¢Ø®Ø± ØµÙˆØ±ØªÙŠÙ† (tags: `vX.Y.Z`, `vX.Y.Z-prev`)
- Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„: Ø£Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø§ÙˆÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
```bash
docker compose pull backend:previous && docker compose up -d backend
```

---

## ğŸ“Š Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Monitoring)
Prometheus Targets:
- Backend `/metrics` (Ø£Ø¶ÙÙ Ù„Ø§Ø­Ù‚Ù‹Ø§)
- Redis Exporter (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
Grafana Dashboards:
- Latency (P50/P95/P99)
- Error Rate
- Cache Hit Rate
- DB Connections

Alert Ù…Ø«Ø§Ù„ (Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹):
- Error Rate > 5% Ù„Ù…Ø¯Ø© 2 Ø¯Ù‚ÙŠÙ‚Ø© â†’ Slack/Webhook

---

## ğŸ“¦ Ø§Ù„ØªØ®Ø²ÙŠÙ† ÙˆØ§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
PostgreSQL:
- ØªØ·ÙˆÙŠØ±: ØªÙØ±ÙŠØº Ø¨Ø³ÙŠØ· (pg_dump ÙŠÙˆÙ…ÙŠ)
- Ø¥Ù†ØªØ§Ø¬: Ø®Ø¯Ù…Ø© Ù…ÙØ¯Ø§Ø±Ø© (ØªÙ„Ù‚Ø§Ø¦ÙŠ)
Redis:
- Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¤Ù‚ØªØ©Ø› Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù†Ø³Ø® ÙƒØ§Ù…Ù„ ÙÙŠ MVP

Script Ù…Ø«Ø§Ù„:
```bash
pg_dump $DATABASE_URL > backup_$(date +%F).sql
```

---

## ğŸ”„ Disaster Recovery & Business Continuity
**ØªÙ…Øª Ø§Ù„Ø¥Ø¶Ø§ÙØ©:** November 8, 2025 (Post Expert Review)

### Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ (Backup Strategy)

#### Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (PostgreSQL):

```yaml
Backup Frequency:
  MVP (Week 1-12):
    - Daily automated backups (3 AM UTC)
    - Retention: 7 days
    - Storage: Platform-managed (Railway/DO)
  
  Production (Week 13+):
    - Automated backups every 6 hours
    - Retention: 30 days
    - Point-in-time recovery: Last 7 days
    - Storage: Separate cloud bucket (AWS S3 / DigitalOcean Spaces)

Backup Encryption:
  - AES-256 encryption at rest (handled by platform)
  - Transfer: TLS 1.3 during upload
  - Access Control: Restricted to admin user only

Backup Testing:
  - Monthly restore test (1st of each month)
  - Validate data integrity after restore
  - Document restore time (should be < 30 minutes for MVP database)

Automation Script:
  ```bash
  #!/bin/bash
  # backup_db.sh - Daily automated backup
  
  DATE=$(date +%Y-%m-%d-%H%M%S)
  BACKUP_DIR="/backups/postgres"
  RETENTION_DAYS=7
  
  # Create backup
  pg_dump $DATABASE_URL | gzip > $BACKUP_DIR/backup_$DATE.sql.gz
  
  # Encrypt backup (optional for extra security)
  gpg --encrypt --recipient admin@bahr.com $BACKUP_DIR/backup_$DATE.sql.gz
  
  # Upload to cloud storage (example: AWS S3)
  aws s3 cp $BACKUP_DIR/backup_$DATE.sql.gz.gpg s3://bahr-backups/postgres/
  
  # Clean up old backups (keep last 7 days)
  find $BACKUP_DIR -name "backup_*.sql.gz*" -mtime +$RETENTION_DAYS -delete
  
  # Verify backup integrity
  gunzip -t $BACKUP_DIR/backup_$DATE.sql.gz
  
  echo "Backup completed: backup_$DATE.sql.gz"
  ```
```

#### Redis Cache:

```yaml
Backup Strategy:
  - NO automated backups (MVP)
  - Rationale: Redis is ephemeral cache only
  - Recovery: Rebuild from PostgreSQL (acceptable delay)
  
  Production (Future):
    - RDB snapshots every 6 hours (if using Redis for sessions)
    - AOF (Append-Only File) for durability
```

#### User Uploads (Phase 2+):

```yaml
When Implemented:
  - Storage: S3-compatible object storage (R2, DO Spaces)
  - Versioning: Enabled (protect against accidental deletion)
  - Backup: Cross-region replication
  - Retention: 90 days for deleted files
```

### Recovery Objectives:

```yaml
Recovery Time Objective (RTO):
  MVP: 4 hours
    - Time to restore database from backup
    - Time to redeploy application
    - Time to verify functionality
  
  Production: 1 hour
    - Automated failover to standby
    - Manual verification and DNS update
  
  Breakdown:
    1. Detection: < 15 minutes (monitoring alerts)
    2. Decision: < 15 minutes (assess severity)
    3. Restore: < 2 hours (database + redeploy)
    4. Testing: < 1 hour (smoke tests + verification)
    5. Communication: < 30 minutes (notify users if needed)

Recovery Point Objective (RPO):
  MVP: 24 hours
    - Maximum data loss: 1 day of analyses
    - Daily backups at 3 AM UTC
    - Acceptable for beta users
  
  Production: 1 hour
    - Continuous replication to standby
    - 6-hour backup snapshots
    - Point-in-time recovery available
```

### Restore Procedures:

#### Database Restore (PostgreSQL):

```bash
# 1. Stop application (prevent new writes)
railway run --service backend pm2 stop all

# 2. Download backup from cloud storage
aws s3 cp s3://bahr-backups/postgres/backup_2025-11-08.sql.gz.gpg ./

# 3. Decrypt backup (if encrypted)
gpg --decrypt backup_2025-11-08.sql.gz.gpg > backup_2025-11-08.sql.gz

# 4. Decompress
gunzip backup_2025-11-08.sql.gz

# 5. Restore to database
# WARNING: This will overwrite existing data!
psql $DATABASE_URL < backup_2025-11-08.sql

# 6. Verify data integrity
psql $DATABASE_URL -c "SELECT COUNT(*) FROM users;"
psql $DATABASE_URL -c "SELECT COUNT(*) FROM analyses;"
psql $DATABASE_URL -c "SELECT MAX(created_at) FROM analyses;"  # Check latest data

# 7. Restart application
railway run --service backend pm2 restart all

# 8. Smoke test
curl -f https://api.bahr.com/api/v1/health
```

#### Full System Recovery (Worst Case):

```yaml
Scenario: Complete platform failure (Railway/DO down)

Steps:
  1. Provision new infrastructure:
     - Spin up new backend instance
     - Create new PostgreSQL database
     - Create new Redis instance
  
  2. Restore database:
     - Download latest backup from S3
     - Restore to new database
     - Verify data integrity
  
  3. Deploy application:
     - Pull latest Docker images
     - Update environment variables (new DB URLs)
     - Deploy backend + frontend
  
  4. Update DNS:
     - Point domain to new infrastructure
     - TTL: 5 minutes (fast propagation)
  
  5. Verify and monitor:
     - Run smoke tests
     - Monitor error rates
     - Check user reports
  
  Estimated Time: 3-4 hours (within RTO)
```

### Secrets & Configuration Backup:

```yaml
Critical Secrets to Backup:
  - JWT Secret Key (SECRET_KEY)
  - Database credentials (DATABASE_URL)
  - Redis URL (REDIS_URL)
  - API keys (OpenAI, Hugging Face)
  - SSL certificates
  - Environment variables (.env.production)

Storage:
  - 1Password / AWS Secrets Manager / HashiCorp Vault
  - NEVER commit to Git
  - Document which team members have access
  
Rotation Schedule:
  - JWT Secret: Every 90 days
  - Database password: Every 180 days
  - API keys: On compromise or annually
```

### Monitoring & Alerting:

```yaml
Critical Alerts (Page Immediately):
  - Database down (> 5 minutes)
  - Backend down (> 3 minutes)
  - Disk usage > 90%
  - Memory usage > 90%
  - Error rate > 10%

Non-Critical Alerts (Email):
  - Backup failed
  - Slow query detected (> 1 second)
  - API latency P95 > 1 second
  - Unusual traffic patterns

Alert Channels:
  - Slack: #bahr-alerts
  - Email: admin@bahr.com
  - SMS: Critical alerts only (production)
```

### Communication Plan:

```yaml
User Communication:
  Minor Issues (< 30 min downtime):
    - Post-mortem in changelog
    - No user notification needed
  
  Major Issues (> 30 min downtime):
    - Status page update: status.bahr.com
    - Twitter/Social media announcement
    - Email to active users (if > 2 hours)
  
  Data Loss:
    - Immediate notification to all affected users
    - Explanation of what was lost
    - Compensation plan (if applicable)

Template:
  "We experienced a technical issue from [TIME] to [TIME] affecting [FEATURE].
   The issue has been resolved. We apologize for the inconvenience.
   If you experience any problems, please contact support@bahr.com"
```

---

## ğŸ§ª Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù‚Ø¨Ù„ ÙƒÙ„ Ù†Ø´Ø± (Pre-Deploy Checklist)
- [ ] Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª Ù…Ø¨Ù†ÙŠØ© Tagged (`backend:vX.Y.Z`, `frontend:vX.Y.Z`)
- [ ] Ù†Ø¬Ø­Øª Ø§Ù„Ù…Ù‡Ø§Ø¬Ø±Ø§Øª Ù…Ø­Ù„ÙŠØ§Ù‹
- [ ] Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ­Ø¯Ø© API (ØªØ­Ù„ÙŠÙ„ØŒ Ù…ØµØ§Ø¯Ù‚Ø©) Ù†Ø§Ø¬Ø­Ø©
- [ ] Ù‚ÙŠØ§Ø³ Ø²Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØª ÙˆØ§Ø­Ø¯ Ø¶Ù…Ù† Ø§Ù„Ù‡Ø¯Ù
- [ ] Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙØ§ØªÙŠØ­ Ø­Ø³Ø§Ø³Ø© ÙÙŠ Git
- [ ] Ù…Ù„Ù CHANGELOG/CRITICAL_CHANGES Ù…ÙØ­Ø¯Ù‘Ø«

---

## â±ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
- ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©: Ù‡Ø¯Ù < 200MB (backend)ØŒ < 300MB (frontend build)
- Ø§Ø³ØªØ®Ø¯Ù… `--no-cache-dir` ÙÙŠ pip Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…
- Ø£Ø¶ÙÙ Ø·Ø¨Ù‚Ø© caching Ù„Ø§Ø­Ù‚Ø§Ù‹ (Poetry + multi-stage)

---

## ğŸ” Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Security Baseline)
- ØªÙØ¹ÙŠÙ„ CORS Ø¨Ù†Ø·Ø§Ù‚ Ù…Ø­Ø¯Ø¯ (localhost/Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ÙØ¹Ù„ÙŠ)
- Ù…Ù†Ø¹ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Ø§Ù„Ø­Ø¯ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª)
- ØªØ³Ø¬ÙŠÙ„ Ù…Ø­Ø§ÙˆÙ„Ø§Øª ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù…Ø¹Ø¯Ù„ (Rate Limit) ÙÙŠ Ø³Ø¬Ù„ Ù…Ø³ØªÙ‚Ù„
- ØªØ£Ø¬ÙŠÙ„ Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© (RLS, JWT Rotation) Ù„Ù…Ø§ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚

---

## ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ø®Ø§Ù† (Smoke Test) Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø´Ø±
```bash
curl -f https://your-domain.com/api/v1/health
curl -f -X POST https://your-domain.com/api/v1/analyze -H 'Content-Type: application/json' -d '{"text":"Ù‚ÙØ§ Ù†Ø¨Ùƒ Ù…Ù† Ø°ÙƒØ±Ù‰"}'
```
Ø¥Ø°Ø§ Ù†Ø¬Ø­Ø§ Ù…Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© JSON ØµØ­ÙŠØ­Ø©ØŒ Ø§Ø¹ØªØ¨Ø± Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø£ÙˆÙ„ Ù†Ø§Ø¬Ø­.

---

## ğŸ“Œ Ù…Ø§ Ù‡Ùˆ Ù…Ø¤Ø¬Ù„ (Deferred Items)
- Kubernetes
- Autoscaling
- Message Queue (Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)
- ML Model Serving (Phase 2+)

---

## ğŸ“ Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹
Ø§Ù„Ù†Ø´Ø± ÙÙŠ MVP Ø¨Ø³ÙŠØ· ÙˆÙ…ØªØ­ÙƒÙ… Ø¨Ù‡: Ø­Ø§ÙˆÙŠØ§Øª + Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙØ¯Ø§Ø±Ø© + Ù…Ø±Ø§Ù‚Ø¨Ø© Ø®ÙÙŠÙØ©. Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø®Ø·ÙˆØ§Øª Ù‚Ù„ÙŠÙ„Ø© ÙˆØ±Ø§Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©. Ø£ÙŠ ØªÙˆØ³Ø¹ Ù„Ø§Ø­Ù‚ Ø³ÙŠÙØ¨Ù†Ù‰ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©.

**Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«:** November 8, 2025
