name: Golden Set Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'dataset/**'
      - '.github/workflows/test-golden-set.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'dataset/**'
  workflow_dispatch:  # Allow manual triggers

jobs:
  test-golden-set:
    name: Test Golden Set Dataset
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov jsonschema
      
      - name: Run unit tests
        run: |
          python -m pytest dataset/tests/test_golden_set_loader.py -v --tb=short
      
      - name: Run schema validation tests
        run: |
          python -m pytest dataset/tests/test_schema_validation.py -v --tb=short
      
      - name: Run all tests with coverage
        run: |
          python -m pytest dataset/tests/ \
            -v \
            --cov=dataset \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-report=html \
            -m "not integration or integration"
      
      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: matrix.python-version == '3.10'
        with:
          file: ./coverage.xml
          flags: golden-set
          name: golden-set-coverage
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
      
      - name: Archive coverage HTML report
        uses: actions/upload-artifact@v4
        if: matrix.python-version == '3.10'
        with:
          name: coverage-html-report
          path: htmlcov/
      
      - name: Validate schema compliance
        run: |
          python dataset/scripts/validate_schema.py
      
      - name: Run quality checks
        run: |
          python dataset/scripts/validate_golden_set.py
      
      - name: Test statistics
        run: |
          echo "=== Test Results Summary ==="
          python -m pytest dataset/tests/ --collect-only -q
          echo "=== Dataset Statistics ==="
          python -c "
          import json
          with open('dataset/evaluation/golden_set_metadata.json') as f:
              meta = json.load(f)
          print(f\"Total verses: {meta['total_verses']}\")
          print(f\"Meters covered: {len(meta['meter_distribution'])}\")
          print(f\"Average confidence: {meta['quality_metrics']['avg_confidence']:.3f}\")
          print(f\"Verification rate: {meta['quality_metrics']['verification_rate']:.1%}\")
          "
  
  validate-schema:
    name: Validate JSON Schema
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install jsonschema
        run: pip install jsonschema
      
      - name: Validate all verses against schema
        run: |
          python dataset/scripts/validate_schema.py
      
      - name: Check schema is valid JSON Schema Draft 7
        run: |
          python -c "
          import json
          from jsonschema import Draft7Validator
          
          with open('dataset/evaluation/golden_set_schema.json') as f:
              schema = json.load(f)
          
          Draft7Validator.check_schema(schema)
          print('✅ Schema is valid JSON Schema Draft 7')
          "
  
  data-quality-check:
    name: Data Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Run data quality validation
        run: |
          python dataset/scripts/validate_golden_set.py
      
      - name: Check for duplicate verse IDs
        run: |
          python -c "
          import json
          
          verses = []
          with open('dataset/evaluation/golden_set_v0_20_complete.jsonl') as f:
              for line in f:
                  verses.append(json.loads(line))
          
          verse_ids = [v['verse_id'] for v in verses]
          duplicates = [vid for vid in verse_ids if verse_ids.count(vid) > 1]
          
          if duplicates:
              print(f'❌ Found duplicate verse IDs: {set(duplicates)}')
              exit(1)
          else:
              print('✅ No duplicate verse IDs found')
          "
      
      - name: Verify metadata consistency
        run: |
          python -c "
          import json
          
          # Load metadata
          with open('dataset/evaluation/golden_set_metadata.json') as f:
              metadata = json.load(f)
          
          # Load actual verses
          verses = []
          with open('dataset/evaluation/golden_set_v0_20_complete.jsonl') as f:
              for line in f:
                  verses.append(json.loads(line))
          
          # Check count matches
          assert len(verses) == metadata['total_verses'], \
              f'Verse count mismatch: {len(verses)} vs {metadata[\"total_verses\"]}'
          
          print(f'✅ Metadata consistent: {len(verses)} verses')
          "
